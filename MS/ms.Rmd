---
title: "Meta-analytic approaches and effect sizes to account for 'nuisance heterogenity' in comparative physiology"
bibliography: ../bib/refs.bib
csl: ../bib/the-journal-of-experimental-biology.csl
output: 
  bookdown::word_document2:
    toc: no
    toc_depth: 6
    number_sections: false
    reference_docx: template.docx
  bookdown::html_document2:
    code_folding: hide
    number_sections: no
    toc: no
    toc_depth: 6
    toc_float: yes
    bibliography: refs.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
  knitr::opts_chunk$set(echo = FALSE, cache = TRUE, message = FALSE, warning = FALSE, tidy = TRUE, fig.width = 10)
  ## numbers >= 10^5 will be denoted in scientific notation,		  ## numbers >= 10^5 will be denoted in scientific notation,
    ## and rounded to 2 digits		  ## and rounded to 2 digits
    options(digits = 2)
    
  pacman::p_load(flextable, tidyverse, equatags, png, magick)  
```

Daniel W.A. Noble$^{1,*}$, Patrice Pottier$^{2}$, Malgorzata Lagisz$^{2}$, Samantha Burke$^{2}$, Szymon M. Drobniak$^{2}$, Rose E.  O'Dea$^{2}$, Shinichi Nakagawa$^{2}$

$^{1}$ Division of Ecology and Evolution, Research School of Biology, The Australian National University, Canberra, ACT 2600

$^{2}$ Ecology & Evolution Research Centre, School of Biological, Earth and Environmental Sciences, University of New South Wales, Sydney, NSW

## **Abstract**

Meta-analysis is a powerful tool to generate quantitatively informed answers to pressing global challenges. By distilling data from broad sets of research designs and study systems into standardized effect sizes, meta-analyses provide physiologists with opportunities to estimate overall effect sizes and understand the drivers of effect variability. Despite this ambition, research designs in the field of comparative physiology can appear, at the outset, as being vastly different to each other because of 'nuisance heterogeneity' (e.g., different temperatures or treatment dosages used across studies). Such differences in treatments across studies has led many to believe that meta-analysis is an exercise in comparing "apples with oranges". Here, we dispel this myth by showing how standardised effects sizes can be used in conjunction with multilevel meta-regression models to both account for the factors driving differences across studies and make them more comparable. We formalise effect size measures (e.g., $Q_{10}$) that provide comparative physiologists with a means to remove 'nuisance heterogeneity' without the need to resort to more complex statistical models that may be harder to interpret. We also describe more general approaches that can be applied to a variety of different contexts to derive 'new' effects sizes and sampling variances opening up new possibilities. By using effect sizes that account for components of effect heterogeneity, in combination with existing meta-analytic models, comparative physiologists can explore exciting new questions and make results from large-scale data sets more accessible, comparable and widely interpretable.

## **Introduction**

Meta-analysis has emerged as the 'gold-standard' across various disciplines for quantitative synthesis and is becoming increasingly more prominent in the field of comparative physiology  [@Gurevitch2018; @Nakagawa2017; @Glass2015]. A meta-analysis provides quantitatively informed answers to research questions by synthesising research results across studies and identifying sources of variation across studies [@Nakagawa2017; @Gurevitch1999; @Gurevitch2018; @Cooper2009; @Arnqvist1995; @Koricheva2013; @Borenstein2019]. Ideally, meta-analyses are part of a systematic review and carefully report upon this entire process to ensure the review and data collation are transparent and reproducible [i.e., see the Preferred Reporting Items for Systematic Reviews and Meta-Analyses in Ecology and Evolution (PRISMA-EcoEvo) protocol, @ODea2021].  Aside from providing an up-to-date overview of a research field there are three major goals of meta-analysis: 1) to provide an overall mean estimate of a treatment effect or relationship, 2) to quantify effect size variance and understand key drivers explaining differences in effects across studies and 3) attempt to identify gaps and publication biases [@Nakagawa2017; @Gurevitch1999; @Gurevitch2018; @Cooper2009; @Koricheva2013; @Borenstein2019]. Meta-analysing independent studies provides greater statistical power and precision than what any individual study on its own would be able to provide - particularly given that most empirical studies are already under-powered in many areas of biology [@Forstmeier2017; @Jennions2003; @Button2013]. By expressing study effects on a common scale (i.e., standardised effect size) we can gain broader insight into the direction and efficacy of a particular treatment effect or the strength of a relationship between two variables of interest [@Gurevitch2018; @Koricheva2013]. Meta-analyses have already provided comparative physiologists with powerful insights on pressing global challenges - from testing whether physiological plasticity can buffer organisms against climate change [e.g, @Seebacher2015] to the degree to which endocrine disrupting chemicals, such as bis-phenol A (BPA), impact aquatic organisms [e.g., @WuSeebacher2020].

Despite its widespread adoption and well-established methodological procedures, meta-analysis is often criticised for mixing 'apples and oranges' -- in other words, mixing effects from studies that lack comparability [@Gurevitch2018; @Arnqvist1995; @Gallo1979; @Carpenter2020; @Stewart2010; @Glass2015]. Lack of comparability could result from studies differing in experimental design, species, measurement variables and sampling units, which can impact the generalisability of meta-analytic results [@Arnqvist1995; @Stewart2010]. For example, experimental designs in the field of comparative physiology can vary greatly in the temperatures or dosages of chemicals that they use in experimental treatments [e.g., @WuSeebacher2020]. To the uninitiated, this concern might not be unfounded given that heterogeneity in effects is often high in ecological and evolutionary meta-analyses [@Senior2016], telling us that the effect size varies a great deal across studies. However, to many, having highly heterogeneous effects "...is the spice of life" [p.g., 519; @Cooperetal2019] because it provides opportunities to explore the reasons for why effects vary within and across studies [@Cooperetal2019; @Borenstein2019; @Gurevitch2018; @Glass2015].

The goal of our review is to briefly overview the process of meta-analysis, making a case for why heterogeneity is a good thing for answering fundamental research problems and guiding research directions. We introduce the idea of 'nuisance heterogeneity', showing comparative physiologists that it can be comfortably dealt with by re-formalising many existing effect sizes measures and/or by using multilevel meta-regression models. Then, we present results from a survey of published meta-analyses in the field of comparative physiology to gauge methodological and meta-analytic practices -- determining what types of effect sizes are commonly used, how often effect size estimates are impacted by 'nuisance heterogeneity' and whether meta-analytic models (i.e., models that account for sampling variance) are commonly applied. We also formalise alternative effect sizes and their associated sampling variance to provide comparative physiologists opportunities to explicitly incorporate 'nuisance heterogeneity' at the effect size level to ease their interpretation. Finally, we describe how more complex treatment differences, such as non-linear dosage differences, can be accommodated using multilevel meta-regression models. We hope that, by expanding the meta-analytic toolkit, it will provide new opportunities for comparative physiologists to address how organisms will cope with rapidly changing environments and anthropogenic stressors in the future.

## **The Apples and Oranges 'Problem' in Comparative Physiology**

Meta-analysis is always concerned with effect heterogeneity; in other words, the factors that drive differences in the direction and magnitude of effects within and across studies [@Nakagawa2017; @Gurevitch2018; @Cooperetal2019; @Borenstein2019]. The concept of heterogeneity is vitally important because it tells us how general findings are likely to be and how much of the variance we see is the result of real biology or methodological differences (not just sampling variance) [@Nakagawa2017; @Borenstein2019]. There are a plethora of phenomena driving effect heterogeneity, some of which are interesting and others that are less so.

Generally, contributors to effect size heterogeneity fall within a number of broad categories. First, sampling variance contributes to heterogeneity; the variability driven by the inherent uncertainty in sampling a given population. We cannot sample the entire population and nor do we necessarily want to. As a consequence, we need to rely on a sub-sample to estimate a population parameter (e.g., correlation between two traits). How many independent samples we collect impacts our precision in estimating the 'true' effect [@Borenstein2019]. In a meta-analysis we formally include sampling variance to remove this source of heterogeneity directly because it is known [@Gurevitch2018; @Koricheva2013]. While unweighted analyses are common, weighting studies makes overall estimates more precise, reliable and less susceptible to publication bias, even if the overall mean itself is unbiased [@Morrissey2016a]. As such, weighting effect size estimates by their inverse sampling variance can be crucial in meta-analysis. Second, there are sociological factors impacting heterogeneity. These include the ease with which novel and significant results are published relative to non-significant results. Low powered studies that do not find an 'effect' or that find an effect in the opposite direction often lead to what is called publication bias [@Jennions2013; @Nakagawa2021b; @Rothstein2005]. Third, real biological processes can drive effect heterogeneity. This is particularly true in comparative physiology where we synthesise data from different species with varying life-histories, habitats, mating systems and reproductive modes. As comparative physiologists, this is the stuff that gets us up every morning! Some variation could result from shared evolutionary history (i.e., phylogeny) or because of the different thermal environments species (or populations) occupy. We can model these biological factors to test predictions from hypotheses that we believe are key players impacting mean effect size and direction. This improves our understanding of the biological world around us and helps inform on future research directions. Finally, methodological factors are also big contributors to effect variability. In some cases, these methodological factors are of direct interest. For example, the methods for measuring an outcome variable can result in different effects, and it is important we know and understand this to determine how experiments can be designed in the future. In other cases, methodological factors might be considered 'nuisance heterogeneity' [following from @Cooperetal2019] -- factors we know vary, but are rather unsurprising to us (Figure \@ref(fig:fig1)). These might include differences in temperature, pH, dosages, water potential etc. While these factors are likely to have an impact on the magnitude of an effect, they might distract from the core interest of a meta-analysis. In some cases, however, the latter factors might actually not be 'nuisance' variables but the main interest of a synthesis. Regardless, in many cases they can result in a more complicated interpretation of an effect measure than what is desired.

```{r, fig1, fig.cap="*Sources of effect size heterogeneity in meta-analyses*. Heterogeneity can come in various forms, from effect measures varying as a result of shared evolutionary history (i.e., phylogeny), different trait types measured, and sources of 'nuisance heterogeneity'. In this example, nuisance heterogeneity is generated by differences in the experimental temperatures at which the animals were tested. However, nuisance heterogeneity can come in various other forms such as differences in dosage, or biochemical variables between used in the experiments. We can control for these types of heterogeniety by reformalising effect sizes and/or using multilevel metaregression as we describe in our review"}
image <- image_read(here::here("figs", "Fig1.png"))
image
```

Besides sampling variance, all the various sources of heterogeneity contribute (to varying extents) to the 'apples and oranges' problem often touted as compromising the reliability of meta-analyses. Indeed, some of this criticism revolves around combining studies that vary in their quality (e.g., observational vs experimental). Combining standardised effects, while ignoring these sources of heterogeneity can indeed weaken the reliability of a meta-analysis. However, many argue that heterogeneity is just what we are interested in synthesizing [@Cooperetal2019; @Borenstein2019; @Gurevitch2018; @Glass2015]. In the words of Gene Glass, the founder of meta-analysis: "Of course it [meta-analysis] mixes apples and oranges; in the study of fruit nothing else is sensible; comparing apples and oranges is the only endeavor worthy of true scientists; comparing apples to apples is trivial" [p.g., 224, @Glass2015]. Whether comparing apples and oranges is a good idea simply boils down to the specific question of interest, the population one wishes to make conclusions about and how heterogeneous effects actually are. If we are interested in gaining insight into 'fruit' then synthesising apples and oranges is the only thing that makes sense. Instead, if we are interested in generalising only to apples, then mixing fruit will not be ideal. However, if we want to understand why different 'fruit' vary in their effects, then we can only ask this question by including all fruit [@Borenstein2019].

We tend to agree with @Glass2015, and his sentiment is of particular relevance to comparative physiology. For example, if we want to understand the impact of a pollutant on reproduction in aquatic organisms, including aquatic mammals and fish would provide answers to this general question, even if their reproductive biology and physiology are different. By synthesizing diverse study outcomes, not only does it allow to report on overall effects (if the question is relevant to ask), but it allows us to also understand critical features of the literature, study systems (e.g., different effects of pollutants on fish and mammal reproduction) and approaches that can explain the diversity of effect outcomes observed. Doing so provides a richer set of conclusions that can draw attention to important sources of variability that might have otherwise been overlooked. Having said that, it is still very important to understand the limitations and diversity of studies included in a meta-analysis, and how this can affect interpretations made -- an important reason why transparency and reproducibility are such a prominent feature of meta-analysis (or ideally should be) [@ODea2021]. The validity of general conclusions to certain questions (e.g., what is the overall effect of a pollutant on reproduction?) will inevitably depend on the homogeneity of effects being synthesized. If the estimate of an overall effect coincides with low heterogeneity estimates then the effects are reasonably consistent [@Borenstein2019]. If, however, an overall effect is accompanied by large heterogeneity estimates, then we would shift focus and explore drivers of that heterogeneity. For example, given the very different physiology of aquatic mammals and fish, understanding an overall combined effect on reproduction may not be particularly relevant, and indeed may even be misleading. Therefore, understanding overall effects in each of these groups separately, and assess the extent to which they differ, may be more useful. 

There are, however, certain types of heterogeneity that transcend different questions or that are simply a 'nuisance' to interpreting effects. In other words, if we compare different varieties of 'apples', is it still fair to synthesize these studies to understand overall effects? In comparative physiology, this situation might be analogous to a meta-analysis that attempts to assess the effects of diet on fish growth across different populations of a widely distributed (cosmopolitan) species. Studies might rear populations of fish under different temperatures, but in the end, they are still all the same fish species, governed by the same thermodynamic effects on growth. In this situation, we are still interested in understanding overall effects, but we may question whether such a conclusion is sensible given the diversity of temperatures applied. If temperature differences are of direct interest, then this variable can be formally incorporated in statistical models. If, however, it is not of primary interest, then it may introduce an unnecessary complication to the interpretation of the effect of diet on fish growth. Here, we focus on meta-analytic tools to circumvent these issues and demonstrate that the ‘apples and oranges’ problem is not really a problem at all.

## **Survey of Meta-Analytic Practices in Comparative Physiology**

Before embarking overviewing strategies to deal with 'nuisance heterogeneity', it is worth first understanding how comparative physiologists are currently conducting meta-analyses and other quantitative syntheses. As discussed above, different types of questions and experimental approaches will mix 'apples and oranges' to varying extents, but this heterogeneity (or basket of fruit) is often the main interest to comparative biologists. We conducted a literature survey to better understand the different types of effect sizes being used, their susceptibility to known sources of methodological / environmental variability across studies, and how these sources are controlled we conducted a literature survey. To accomplish this goal, we searched for meta-analyses and comparative analyses that tackled questions using physiological data compiled from animal studies across multiple species. We were specifically interested in asking: 1) what type of effect size was used within the quantitative synthesis? 2) based on the methods provided, was the effect size likely susceptible to continuous variation in how treatments were applied (e.g., for contrast-based effects) or the conditions under which traits were measured (i.e., for correlations) across studies (i.e., 'nuisance heterogeneity')? 3) If so, was the variation accounted for in the effect size or during analysis? and finally, 4) how many analyses used 'weighted' meta-analytic models?

#### *Literature Search and Survey Data Collection*

All searches were conducted in Scopus between May 16 - 18, 2021. Briefly, we first did a series of pilot searches (detailed in Supplementary Materials) to refine our search query [See @Foo2021 for an overview of this process]. We searched for studies that included: 'meta-analysis', 'meta regression' , 'comparative analysis', 'comprehensive analysis' 'global analysis' or 'macro physiology' in their title and abstract, restricting our search to key comparative physiology journals (detailed in Table S1 and S2 - Supplementary Materials) within the last 6 years. We expected this to provide a contemporary overview of quantitative syntheses in comparative physiology while making the survey and screening feasible. We acknowledge that this may have missed some important, and influential, quantitative syntheses in the field of comparative physiology, but likely provided a random sample to inform on the questions we sought to address (see below).

We included comparative / meta-analyses that were focused on comparative physiological questions. Narrative reviews and comments were not considered because they did not collate quantitative data from the literature. Studies needed to have collected physiological trait data from the literature such as hormones, thermal physiology (CTmax, CTmin, thermal preferences, thermal breadth, LT50, lethal thresholds), metabolic rates (routine, maximum, and minimum metabolic rate, aerobic scope), enzyme reaction rates and concentrations, oxidative stress and consequences (e.g., DNA damage, teleomere attrition), performance measurements (e.g., heart rates, sprint speed, swim speed, growth rates), body composition (e.g., fatty acid profiles) and immune traits (e.g., cell function, antibodies). Studies were also included if they measured the relationship between physiological traits and body size (e.g., metabolic scaling), reproductive allocation, or survival across taxa. Studies on behavior were only included if the synthesis was explicitly interested in the proximate physiological drivers of behavioral variation. We also included meta-analyses that quantified plasticity in physiological traits in response to environmental variation. While many studies in comparative physiology collect data as part of a comparative analysis, we focus here only on studies collating data from existing literature because this is the major data source in quantitative syntheses. Quantitative syntheses interested in phenology, bio-mechanics, sexual size dimorphism (i.e., SSD, except if the study was interested in sexual differences in physiological traits), those focused on validating physiological methodology, or characterising population genetic structure, gene transcription and quantitative genetics were excluded. There were also meta-analyses that focused on colour evolution and contrast which varied in their goals but were most often not focused on physiological questions. As such, these studies were also excluded. We restricted our focus to animal studies because most plant synthesis papers were focused on ecological (e.g., quantified changes in abundance and distribution of species) or agricultural questions (e.g., studies on soil microbial function, nitrogen and phosphorus capture, methane output and greenhouse gas emissions).

All title, abstract and full text screening was done by two people (DWAN and ML). Any conflicts or disagreements were resolved by discussion and a consensus on a paper was reached. Out of the 417 papers originally identified, 79 full texts were screened for eligibility, and we included a total of 62 for final data extraction. For full details on the search strings used, dates searched, the number of papers found, and our PRISMA flowchart (along with reasons for exclusion at the full text stage) we refer readers to the *Supplementary Information*. To address our questions, we categorised effect sizes as falling into the following categories: Response Ratio (lnRR), Standardised Mean Differences (SMD; e.g., Hedges d, g or Cohen's d), Correlation or Fisher's Z -transformed Correlation, Regression Slopes (Slopes), Risk Ratios, or whether the paper analysed the raw data or summary statistics directly (i.e., means/proportions) (which we label as 'raw'). For all other effects we labelled as 'other'. To determine whether effect sizes were likely to vary based on some underlying continuous variable or were dependent on the context in which traits were measured, we assessed whether authors: 1) acknowledged this explicitly in the paper or 2) accounted for it in their models. If it was not clear, two of us (DWAN & PP) discussed the paper, and made a decision about whether the effect measure was likely to be impacted. For example, trait means, such as ectothermic metabolic rate (i.e., raw/mean/proportion-based effect size), will vary depending on the temperature being measured. The magnitude of differences between two treatments (e.g, contrast-based effect sizes - SMD or lnRR) might depend on the pH or dosage used in treatments, and the strength of relationship between two variables (e.g., correlation between behaviour and metabolism) might depend on the temperature context under which metabolic rate or behaviour were measured. Given the high heterogeneity in effects used in comparative physiology, we expected 'nuisance heterogeneity' to be common to most effect sizes. We categorised the types of statistical models fit in each study as: 1) fixed-effect meta-analysis; 2) random effects meta-analysis (i.e., intercept only model, but has random study effects); 3) multilevel meta-analysis (i.e., intercept only model, but has multiple random effect levels such as study, species and observation-level random effects); 4) meta-regression models (i.e., a multilevel or random effect model with fixed effects - including random effects); 5) weighted regression models (including mixed effect models); and 6) linear regression models (including linear and generalised linear mixed effect models, and phylogenetic least squares models) [see @NakagawaSantos2012 for discussion of models]. Notably, only model types 1-5 are weighted models because they weight effect sizes based on the inverse of their sampling variance or sample size.

#### *Current Meta-analytic Practices in Comparative Physiology*

```{r setup2, include=FALSE}
rm(list=ls())

pacman::p_load(dplyr,ggplot2,here, pander, janitor, patchwork, forcats)

# loading data
raw <- read.csv(here("data","MA_CompPysio_Survey.csv"))
metadata <- read.csv(here("data","MA_CompPysio_Survey_metadata.csv"))

# tidying data
dat <- raw
names(dat) <- metadata$Procesed.Column.Name[match(names(dat), metadata$Raw.Column.Name)]

# tidying categorical options
dat$meta_analysis_self_described <- factor(gsub(" \\(.*", "", dat$meta_analysis_self_described), levels = c("yes","no","unclear/other"))
dat$comparative_physiology_main_focus <- factor(gsub(" \\(.*", "", dat$comparative_physiology_main_focus), levels = c("yes","no","unclear/other"))

# fixing format of journals

#dat$DOI[dat$journal=="2017"] # Typo
dat$journal[dat$journal=="2017"] <- "Biology Letters"

#dat$DOI[grep("Proceedings", dat$journal)] # all the same journal
dat$journal[grep("Proceedings", dat$journal)] <- "Proceedings of the Royal Society B: Biological Sciences"

# standardising DOI format
dat$DOI <- gsub(".*org/", "", dat$DOI)
dat$DOI <-gsub(".* ", "", dat$DOI)

# ggplot2 theme for plots
background.colour <- "white"
text.colour <- "black"
# Font Choice
#loadfonts()
text.font <- "Arial"

tm <- theme(panel.background = element_rect(fill = background.colour),
            plot.background = element_rect(fill = background.colour),
            panel.grid = element_blank(),
            text =  element_text(family = text.font, colour = text.colour),
            axis.text = element_text(colour = text.colour),
            axis.title.x = element_text(margin = margin(10,0,0,0)),
            axis.title.y = element_text(margin = margin(0,10,0,0)),
            axis.line = element_line(colour = text.colour, size = 0.5),
            axis.ticks = element_line(colour = text.colour, size = 0.5),
            plot.title = element_text(hjust = 0.5),
            legend.background = element_rect(fill = background.colour),
            legend.key = element_rect(fill = background.colour),
            plot.margin = margin(6,6,6,6)) 

effects <- dat %>% dplyr::group_by(effect_size_type) %>% janitor::tabyl(effect_size_type) %>%
  dplyr::summarise(SMD = dplyr::if_else(grepl("SMD", effect_size_type), n, 0),
                  lnRR = dplyr::if_else(grepl("Response Ratio", effect_size_type), n, 0),
                    Zr = dplyr::if_else(grepl("correlation", effect_size_type), n, 0),
                 Other = dplyr::if_else(grepl("other|Q10", effect_size_type), n, 0),
                 Means = dplyr::if_else(grepl("mean/proportion/raw", effect_size_type), n, 0),
                 lnCVR = dplyr::if_else(grepl("lnCVR", effect_size_type), n, 0),
                 Slope = dplyr::if_else(grepl("slope", effect_size_type), n, 0)) %>% 
  colSums(.) %>% data.frame(effect = names(.), n = .) %>% mutate(prop = n / sum(n)) %>% arrange(prop)

hetero <- dat %>%  janitor::tabyl(cont_moderator_variable)
hetero_dealt <- dat %>%  filter(!cont_moderator_variable_modelled=="") %>% janitor::tabyl(cont_moderator_variable_modelled)
weighted <- dat %>% janitor::tabyl(meta_analysis_weighted) 
weighted_meta <- dat %>% filter(meta_analysis_self_described == "yes") %>% janitor::tabyl(meta_analysis_weighted) 

summary <-  dat %>% dplyr::group_by(stat_model_type) %>% janitor::tabyl(stat_model_type) %>%
  dplyr::summarise(`Multilevel Meta-analysis Model` = dplyr::if_else(grepl("multilevel meta-analysis", stat_model_type), n, 0),
                  `Multilevel Metaregression Model` = dplyr::if_else(grepl("meta-regression models", stat_model_type), n, 0),
                    `Linear Regression` = dplyr::if_else(grepl("linear regression", stat_model_type), n, 0),
                 Other = dplyr::if_else(grepl("unclear/other", stat_model_type), n, 0),
                 `Vote Counting` = dplyr::if_else(grepl("vote counting", stat_model_type), n, 0),
                 `Weighted Regression` = dplyr::if_else(grepl("weighted regression including mixed effects models", stat_model_type), n, 0),
                 `Random Effects Model` = dplyr::if_else(grepl("random-effects meta-analysis", stat_model_type), n, 0)) %>% 
  colSums(.) %>% data.frame(effect = names(.), n = .) %>% mutate(prop = (n / sum(n))) %>% arrange(effect)
rownames(summary) <- NULL

het_reported <- dat %>%  filter(!heterogeneity_reported=="N/A (e.g. they conducted unweighted meta-analysis)") %>% mutate(heterogeneity_reported = if_else(heterogeneity_reported == "unclear/other (add comment)", "other", heterogeneity_reported)) %>% janitor::tabyl(heterogeneity_reported)
```

Quantitative syntheses in comparative physiology commonly analyse raw summary statistics (`r with(effects, effects[effect == "Means","prop"])*100`% of studies), followed closely by Fishers transformed correlation coefficients (Zr) (`r with(effects, effects[effect == "Zr","prop"])*100`% of studies), standardised mean differences (SMD) and log response ratios (lnRR) (`r with(effects, effects[effect == "SMD","prop"])*100`% and `r with(effects, effects[effect == "lnRR","prop"])*100`%, respectively; Figure \@ref(fig:figsurv)A). In many cases, studies make use of multiple effect size measures. Approximately `r with(hetero, hetero[cont_moderator_variable == "yes","percent"])*100`% of effect sizes used within the study we deemed to be impacted by 'nuisance heterogeneity' in some form or another (Figure \@ref(fig:figsurv)B), but of the studies where this was the case, only `r with(hetero_dealt, hetero_dealt[cont_moderator_variable_modelled == "yes","percent"])*100`% of the studies clearly dealt with it (Figure \@ref(fig:figsurv)B); often through meta-regression modelling. Overall, `r with(weighted, weighted[meta_analysis_weighted == "weighted model","percent"])*100`% of studies used a weighted meta-analytic model, however, of the studies self described as 'meta-analyses', `r with(weighted_meta, weighted_meta[meta_analysis_weighted == "unweighted model","percent"])*100`% (N = `r with(weighted_meta, weighted_meta[meta_analysis_weighted == "unweighted model","n"])` of `r with(weighted_meta, sum(weighted_meta[,"n"]))`) did not account for sampling variance. Many studies used 'Linear Regression' (including linear and generalised linear mixed effects models) as the main type of model fit to the data (Figure \@ref(fig:figsurv)C). Of the studies using weighted meta-analytic models `r with(het_reported, sum(het_reported[1:2,"percent"])*100)`% (N = `r with(het_reported, sum(het_reported[1:2,"n"]))` meta-analyses) did not report any measure of heterogeneity, which is unfortunate given how important these measures are to interpreting effects.

```{r, figsurv, fig.wid = 16.833333, fig.height=6.611111,fig.cap="**Summary of meta-analytic practices in comparative physiology.** (A) Different types of effect measures commonly used in meta-analyses and their relative frequency of use. (B) How many meta-analyses where ‘nuisance heterogenity’ have the potential to impact effect sizes, and the proportion of studies explicitly dealing with nuisance heterogenity. (C) Frequency of analytical approaches used to analyse effect measures. Note that only ‘Weighted Regression’, ‘Random Effects Models’, ‘Multilevel Metaregression Models’ and ‘Multilevel Meta-analysis Models’ are weighted models. The results of this survey were drawn from 62 studies in comparative physiology."}
p1 = dat %>% dplyr::group_by(effect_size_type) %>% janitor::tabyl(effect_size_type)  %>% 
  dplyr::summarise(SMD = dplyr::if_else(grepl("SMD", effect_size_type), n, 0),
                  lnRR = dplyr::if_else(grepl("Response Ratio", effect_size_type), n, 0),
                    Zr = dplyr::if_else(grepl("correlation", effect_size_type), n, 0),
                 Other = dplyr::if_else(grepl("other|Q10", effect_size_type), n, 0),
                 Means = dplyr::if_else(grepl("mean/proportion/raw", effect_size_type), n, 0),
                 lnCVR = dplyr::if_else(grepl("lnCVR", effect_size_type), n, 0),
                 Slope = dplyr::if_else(grepl("slope", effect_size_type), n, 0)) %>% 
  colSums(.) %>% data.frame(effect = names(.), n = .) %>% mutate(prop = n / sum(n)) %>% arrange(effect) %>% 
  mutate(effect = fct_relevel(effect, c("Other", "Zr", "lnRR", "SMD", "lnCVR", "Slope", "Means"))) %>% 
  ggplot() + tm + 
  geom_col(aes(x = effect, y = prop), width = 0.5, fill = "black", colour = text.colour, size = 0.5) +
  scale_y_continuous(expand=c(0,0), limits = c(0,0.35)) +
  labs(x = "Effect Size",
       y = "Frequency") +
  coord_flip()

p2 = dat %>% mutate(cont_moderator_variable_modelled = if_else(cont_moderator_variable_modelled == "", "N/A", cont_moderator_variable_modelled)) %>% 
  ggplot() + tm +
  geom_bar(aes(x = cont_moderator_variable,
               fill = cont_moderator_variable_modelled,
               y = ..count../sum(..count..)), width = 0.5,
           colour = text.colour, size = 0.5) +
  scale_y_continuous(expand=c(0,0), limits = c(0,1)) +
  scale_fill_viridis_d() +
  theme(legend.position = c(0.45, 0.8)) + 
  labs(x = "Nuisance Heterogeneity?",
       y = "Frequency",
       fill = "Modeled Nuisance\nHeterogeneity?") 

p3 <- summary %>% 
  mutate(effect = fct_relevel(effect, c("Other","Vote Counting", "Linear Regression", "Weighted Regression", "Random Effects Model", "Multilevel Meta-analysis Model", "Multilevel Metaregression Model"))) %>% 
  ggplot() + tm +
  geom_col(aes(x = effect, y = prop), width = 0.5, fill = "black", colour = text.colour, size = 0.5) +
  scale_y_continuous(expand=c(0,0),limits = c(0,0.4)) +
  labs(x = "Analytical Approach",
       y = "Frequency") +
  coord_flip()

p1 + p2 + p3 + plot_annotation(tag_levels = c("A"), tag_prefix = "(", tag_suffix = ")")

```

## **Opening Up New Opportunities in Comparative Physiology: Expanding the Breadth of Effect Sizes to Deal with "Nuisance Heterogeneity"**

#### *Common Effect Sizes and Sampling Errors that are Useful in Comparative Physiology*

Meta-analysis requires comparative physiologists to make use of effect sizes that are suitable for answering their specific question. The key features of all effect sizes used in meta-analyses are that: 1) they are statistical parameters that have been placed on a common scale so that they can be compared across studies and 2) they have some associated measure of precision (i.e., sampling variance) [@Koricheva2013; @Borenstein2009; @Schmid2021]. Effect sizes in comparative physiology are quite variable; they can be the mean difference between two groups [e.g., difference in mean between a control and treatment group; e.g., @WuSeebacher2020], the slope of a regression (e.g., between body size and metabolic rate), a correlation between two variables (e.g., between hormone levels and behaviour), or even the raw mean (or variance) itself [e.g., comparing CTmax or CTmin across species - e.g., @Sunday2014]. In many cases, different effect sizes might be used depending on the question. For example, to investigate the effect of temperature on a physiological trait, one can compile studies experimentally manipulating temperature and analyse the mean 'effect' by creating contrast-based effect sizes, or alternatively, just model the trait in each temperature treatment. The choice as to which one to use boils down to the types of data available from primary studies, the specific question of interest, and whether studies are observational or experimental in nature. Considering our temperature example above, if we are interested in the magnitude of change between temperature treatments, we may want to use a contrast-based effect size, such as the log response ratio $\ln{RR}$. Instead, if we are interested in how the mean of some physiological trait changes with temperature, we may model the mean itself. In the latter scenario, as long as all the means are measured in the same units (e.g., Celsius; or can be converted to the same units) then the mean may provide the desired answer to the original question. We provide details on different effect measures and associated sample sizes in Table \@ref(tab:tablea).

```{r tablea, echo = FALSE, tab.cap = "Common effect sizes used throughout meta-analyses in comparative physiology, their associated sampling variances and examples on when they might be used. M: mean; SD: standard deviation; N: sample size; CTmin: critical thermal minimum; CTmax: critical thermal maximum; BPA: bisphenol A."}

FitFlextableToPage <- function(ft, pgwidth = 6){

  ft_out <- ft %>% autofit()

  ft_out <- width(ft_out, width = dim(ft_out)$widths*pgwidth /(flextable_dim(ft_out)$widths))
  return(ft_out)
} 

# I'm just listing a bunch here, but we should think about what we want to include. Here's an example of how we can make a table with all equations. Fun! Really useful website here: https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference. Something wrong with character coding when rendering word document. Has to do with the log odds ratio equation. Renders fine in html, but just stops when word
names <- c("Mean",
           "Log Standard deviation, lnSD",
           "Log Response Ratio, lnRR",
           # leave this for now??? - we introduce this later
           "Standardised Mean Difference, SMD",
           "Zr (Fisher Transformation of \n correlation Coefficient, r)")
           #"Log Odds Ratio",
           #"")

# the index i is not really applied consistently so I am adding it more (to do)
# we shoudl discuss what kinds of notations we want to use consistely
           
eqns_yi <- c("M",
             "\\ln{SD} + \\frac{1}{2(N - 1)}",
             # Senior will have a better version but this is good for now
             "\\ln \\left( \\frac{M_{1}}{M_{2}}\\right)",
             "\\frac{\\left( M_{2} - M_{1}\\right)}{SD_{p}}J",
             # we need to spell out SD_p somewhere
             "\\frac{1}{2}log\\left( \\frac{1+r}{1-r}\\ right)")
             #"log\\left(\\frac{y_{i2}+0.5}{n_{i2}-y_{i2}+0.5}\\right) ",
             #"- log\\left(\\frac{y_{i1}+0.5}{n_{i1}-y_{i1}+0.5}\\right)")
             
# Just placeholders for now
eqns_vi <- c("\\frac{SD^2}{N}",
             "\\frac{1}{2(N - 1)}",
             "\\frac{SD_{1}^2} {M^2_{1}N_{1}} + \\frac{SD_{2}^2} {M^2_{2}N_{2}}",
             "\\frac{N_{1} + N_{2}}{N_{1}N_{2}} + \\frac{SMD^2}{2(N_{1} + N_{2})}",
             # see my commenst
             "\\frac{1}{N - 3}")
             #"\\frac{s_{i}^2}{n_{i}}",
             #"")

# Maybe add some examples for each effect size in a new column. SHould help
eg <- c("CTmin, CTmax, Metabolic Rate (MR)",
        "Variability in CTmin, CTmax, MR",
        "Ratio between BPA treatment (BPA-exposed group) and control (no BPA)",
        "Difference in immune response between males and females or performance difference in the presence of stressor compared to absence of stressor",
        "Relationship between sex hormones and immune responses or metabolic rate and behaviour")

table_fin <- data.frame(names, eqns_yi, eqns_vi, eg)

footnotes <- c("Notes: J = 1 - \\frac{3}{4\\left(N_{1} + N_{2} - 2\\right) - 1}",
               "SD_{p} = \\sqrt \\frac{\\left( N_{1}-1 \\right)SD_{1}^2 + \\left( N_{2}-1 \\right)SD_{2}^2}{N_{1} + N_{2} - 2}")

# Note: It is esssential that you be clear that the function 'compose' is exported from the flextable package. That's because purr also has the same function, so it gets messy.
tablea <- flextable(table_fin)                                                                                %>% 
          flextable::compose(j = 1:4, part = "header", value = as_paragraph(as_b(c("Effect Measure", "Definition", "Sampling Variance", "Examples")))) %>% 
          flextable::compose(j = 2:3, value = as_paragraph(as_equation(c(eqns_yi, eqns_vi))))             %>%
          flextable::compose(j = 4, value = as_paragraph(eg))             %>%
          flextable::width(j = 1, 3)                                                                          %>% 
          flextable::width(j = 2, 2) %>% 
          flextable::width(j = 4, 5) %>% 
          flextable::footnote(i = 4, j = 1, value = as_paragraph(as_equation(footnotes)),
               ref_symbols = c("a"),
               part = "body", inline = TRUE)
          

FitFlextableToPage(tablea, pgwidth = 8)

```

#### *Expanding the Scope of Effect Size Metrics in Comparative Physiology*

As can be seen in Table \@ref(tab:tablea), none of the effect measures control for 'nuisance heterogeneity'. For example, the magnitude of lnRR or SMD might depend on just how different the temperatures, dosages, pH or water potential applied in each treatment. The same applies for modelling the means. For example, standard metabolic rate (SMR) is temperature dependent. As such, one needs to standardise the temperature measurement to compare across studies [@White2006; @Uyeda2017] (if, of course, temperature is not of interest in of itself). While we could model this explicitly, this may not always be desirable. It can often be useful to standardise the effect to both ease its interpretation and simplify modelling. In Box 1 we provide readers with guidance on how comparative physiologists can apply corrections to the effect measure itself. We highlight two examples in the box focusing mainly on generality. Below, we show how to formalize a traditional effect size, $lnRR$, into a common measure of interest to comparative physiologists, $Q_{10}$, and show how this new effect size can capture “nuisance heterogeneity”. 

#### *Comparing Changes in Mean Physiological Rates,* $Q_{10}$

A common experiment in comparative physiology is to manipulate the temperature organisms experience and measure some physiological rate (e.g., metabolic rate). Using the effect size measures in Table \@ref(tab:tablea) would result in the effect sizes varying with the temperatures applied within and across across studies contributing to 'comparability' issues. For example, an effect size for a temperature manipulation of 10°C would be larger than an effect size for a temperature manipulation of 5°C (see Figure \@ref(fig:fig1)). As such, it is common to standardize effects by temperature. One common effect size measure already used in comparative physiology to compare physiological rates is the temperature coefficient $Q_{10}$ [e.g., @Rodgers2021; @Seebacher2015; @Havird2020]. This effect size describes the multiplicative change in physiological rates across a 10°C temperature change. Higher $Q_{10}$ values indicate larger changes in physiological rates. However, currently there is no formal sampling variance associated with $Q_{10}$ in the literature, making it challenging to make use of the full power of weighted meta-analytic models. Interestingly, $Q_{10}$ can be seen as a variant of *lnRR*, meaning that we can derive a $Q_{10}$- based effect size and sampling error using the well-known mathematical properties of *lnRR*. This opens up the meta-analytic toolbox and improves upon our ability to account for well known sources of non-independence that are typical in meta-analysis [@Lajeunesse2011; @Noble2017].

Prior to showing how the relevant $Q_{10}$ effect size can be calculated it is useful to understand its similarities to *lnRR*. The *lnRR* described by @Hedges1999 and extended by @Lajeunesse2015 and can be calculated as follows [but see also @Senior2020]:

$$
\begin{equation} 
  \begin{aligned}
  \ln{RR} = \ln\left ( \frac{M_{1}}{M_{2}}\right )
  \end{aligned}
  (\#eq:lnRR)
\end{equation} 
$$

$$
\begin{equation} 
  s^2_{lnRR} = \left ( \frac{SD_{1}^2}{N_{1}M_{1}^2}\right ) + \left ( \frac{SD_{2}^2}{N_{2}M_{2}^2}\right )
  (\#eq:slnRR)
\end{equation} 
$$

In equation \@ref(eq:lnRR), $M_{1}$ is the mean of group 1 (e.g., a control group), where as $M_{2}$ is the mean of group 2 (e.g., a treatment group). The mean, $M_{i}$, for group *i* can be any measurement type (e.g. a physiological rate, mass etc) so long as the measurement variable is ratio scale. Natural log transformation of this ratio makes the effect size normally distributed which is commonly assumed by meta-analytic models. Equation \@ref(eq:slnRR) is the analytical solution for *lnRR*'s sampling variance where, $SD_{1}^2$ and $SD_{2}^2$ is the sample variance in group 1 and 2, respectively and $N_{1}$ and $N_{2}$ is the sample size in group 1 and 2.

The equations for *lnRR* and its sampling variance allow us to extend this to $Q_{10}$ based effect sizes. Recall that $Q_{10}$ is described as follows:

$$
\begin{equation} 
  Q_{10} = \left( \frac{R_{2}}{R_{1}} \right)^{ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
  (\#eq:q10)
\end{equation} 
$$ 

Here, $R_{1}$ and $R_{2}$ are mean physiological rates and $T_{1}$ and $T_{2}$ are the temperatures that these rates are measured. Natural log transformation of equation \@ref(eq:q10) leads to the following log transformed $Q_{10}$:

$$
\begin{equation} 
  lnRR_{Q_{10}} = ln\left( \frac{R_{2}}{R_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
(\#eq:lnq10)
\end{equation} 
$$ 

Equation \@ref(eq:lnq10) is essentially a temperature corrected equivalent of lnRR when the numerator and denominator are measured at different temperatures. This allows one to compare the mean of two temperature treatments directly regardless of the temperatures that these groups have been measured. Here, we will refer to this as the log $Q_{10}$ response ratio, $lnRR_{Q_{10}}$. Notably, using this effect rather than the traditional $Q_{10}$ has two statistical advantages: 1) zero becomes biologically meaningful as 0 means two rates are the exactly the same and 'significantly different from zero' means that two rates are significantly different to each other and 2) $lnRR_{Q_{10}}$ is more likely to satisfy the assumption of residual normality than $Q_{10}$ (see @Hedges1999). The recognition of this equivalence means that we can calculate the sampling variance for equation \@ref(eq:lnq10) as follows:

$$
\begin{equation} 
  s^2_{lnRR_{Q_{10}}} = \left( \frac{SD_{2}^2}{R^2_{2}N_{2}} + \frac{SD_{1}^2}{R^2_{1}N_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }^2
  (\#eq:Vlnq10)
\end{equation} 
$$

#### *Formalising Effect Size Metrics that Compare Changes in Variability Across Treatments in the Presence of "Nuisance Heterogeneity"*

@Nakagawa2015 recently proposed analogous effect size estimates to *lnRR* that allow for comparisons of changes in variance between two groups, the log variance ratio (*lnVR*) and the log coefficient of variation (*lnCVR*). Like *lnRR*, *lnVR* and *lnCVR* are ratios that describe the relative difference in trait variability between two groups. We refer readers to @Nakagawa2015 for the equations describing *lnVR* and *lnCVR*, but these can easily be extended to their $Q_{10}$ analogues (and associated sampling variances) as follows:

$$
\begin{equation} 
lnVR_{Q_{10}} = ln\left( \frac{SD_{2}}{SD_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
(\#eq:lnq10VR)
\end{equation} 
$$ $$
\begin{equation} 
s^2_{lnVR_{Q_{10}}} = \left( \frac{1}{2\left( N_{2}-1 \right)} + \frac{1}{2\left(N_{1} - 1\right)} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }^2
(\#eq:slnq10VR)
\end{equation} 
$$

Equations \@ref(eq:lnq10VR) and \@ref(eq:slnq10VR) describe the change in physiological rate variance (eqn \@ref(eq:lnq10VR)) relative to a 10°C temperature change, along with its sampling variance (eqn \@ref(eq:slnq10VR)). While this is a useful metric, as discussed by @Nakagawa2015, there is often a strong mean-variance relationship that needs to be accounted for in analysing changes in variance. As such, we can calculate the coefficient of variation, which standardises changes in variance for changes in means as follows:

$$
\begin{equation} 
lnCVR_{Q_{10}} = ln\left( \frac{\text{CV}_{2}}{\text{CV}_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
(\#eq:lnq10CVR)
\end{equation} 
$$ $$
\begin{equation} 
s^2_{lnCVR_{Q_{10}}} = \left[ \frac{(\text{SD}_{1})^2}{N_{1}({R}_{1})^2} + \frac{(\text{SD}_{2})^2}{N_{2} ({R}_{2})^2} + \frac{1}{2\left( N_{1}-1 \right)} + \frac{1}{2\left(N_{2} - 1\right)} \right]{ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }^2
(\#eq:slnq10CVR)
\end{equation} 
$$

where $CV$ is the coefficient of variation defined as $SD / R$. Whether one choose to use SD or CV-based effect size depends on questions at hand [See @Nakagawa2015; @Senior2020].

Our example using $Q_{10}$, a well-known effect measure in comparative physiology, shows how common effect size's can be re-formalised to account for 'nuisance heterogeneity', in this case temperature. In doing so, we are making assumptions about the nature of temperature effects on an effect size. Nonetheless, we can apply similar approaches to other commonly used effect size metrics. We describe more generally how this can be done in Box 1, applying similar principles to standardise temperature differences for slopes and standardised mean differences.

## **Meta-Analytic Models to Control for and Investigate Heterogeneous Effects Within and Across Studies**

It will not be possible to always derive an effect size that completely controls for 'nuisance heterogeneity' at the effect size level all the time. This limitation is partly because treatment effects may not be simple linear or exponential functions of the mean response, making the effect sizes we discuss above unsuitable [e.g., thermal performance curves; @Noble2018]. For example, dosages applied to treatments can follow quite complex non-linear (e.g., quadratic) relationships in relation to some mean response. When this occurs, we recommend comparative physiologists to apply meta-regression approaches, controlling for 'nuisance heterogeneity' as a moderator. In many cases, this will be the easiest, or even preferred approach because exploring drivers of heterogeneity is of prime interest in most meta-analyses anyway. Nonetheless, there are some simple statistical approaches a comparative physiologist can use to make the overall effects more easily interpretable, allowing one to control for 'nuisance heterogeneity', while also testing other biological moderators of interest [@Schielzeth2010]. Before diving into meta-regression models, we will first overview the meta-analytic models commonly used.

#### *Multi-level Meta-Analysis when the Overall Effect is of Interest*

A common goal of meta-analysis is to obtain an overall meta-analytic mean effect size estimate and some form of uncertainty around that mean, like a 95% confidence interval (CI). Including a prediction interval (PI) can also be useful (discussed below) [@Nakagawa2021c]. Estimating an overall mean and 95% CI is generally done with a simple random effects or multilevel meta-analytic model that accounts for effect size sampling error [@Nakagawa2017; @NakagawaSantos2012]. More often than not, meta-analyses in comparative physiology will have complex hierarchical structure. For example, multiple effect sizes may be taken from a single study on traits measured on the same individuals, or come from many different species that share an evolutionary history [@Cinar2021; @Noble2017]. As such, it is far more likely that comparative physiologists will need to apply a multilevel meta-analytic model to control for the various sources of non-independence, and whenever possible, they should [@Cinar2021; @NakagawaSantos2012; @Song2021; @Nakagawa2021; @Noble2017]. Multilevel models are also extremely useful in describing the various sources contributing to effect size variance (a feature we describe below). For the purpose of our discussion, we will assume one needs to use more advanced multilevel models. Having said that, in some instances, it may be sufficient for a meta-analysis to make use of traditional random effects models. We refer readers to excellent reviews and books that overview the distinctions between common (fixed) effect, random effect and multilevel models and when one might want (or not want) to apply these models [@Nakagawa2017; @NakagawaSantos2012; @Koricheva2013; @Borenstein2009; @Schmid2021].

Assume that we are interested in understanding the overall effect of, say, stress (i.e., corticosterone - CORT) on reproduction [e.g., see @Podmola2018]. We might extract data from studies manipulating corticosterone in bird eggs. Of course, these studies are diverse, spanning many species and applying different dosages of corticosterone and are working across many species. If the studies are experimental in nature, then a standardised effect size, such as $ln_{RR}$ or SMD, might be applicable. We then might fit an overall multilevel meta-analytic model as follows: 
$$
\begin{split}
Y_{i} = \beta_{0} + a_{k[i]} + sp_{k[i]} + s_{j[i]} + e_{i} + m_{i} \\
a_{k[i]}\sim N(0, \sigma^{2}_{phylogeny}\textbf{A}), \\
sp_{k[i]}\sim N(0, \sigma^{2}_{species}\textbf{I}), \\
s_{j[i]}\sim N(0, \sigma^{2}_{study}\textbf{I}), \\
e_{i}\sim N(0, \sigma^{2}_{residual}\textbf{I}), \\
m_{i} \sim N(0, v_{i}\textbf{I}) \\
\end{split}
$$

where $Y_{i}$ is the *i*th effect size (*i* = 1 ... $N_{ES}$, the number of effect sizes), $\beta_{0}$ is the overall meta-analytic mean, $a_{k[i]}$ is the phylogenetic effect (a random effect) for species *k* applied to effect size *i* [i.e., species effects because of shared evolutionary history, @Cinar2021]. Phylogenetic effects are assumed to be normally distributed deviates sampled from a distribution with a mean of 0 and variance $\sigma^{2}_{phylogeny}$ [i.e., *N*$(0, \sigma^{2}_{phylogeny}\textbf{A})$], where $\textbf{A}$ is a phylogenetic correlation matrix derived from a phylogenetic tree. $sp_{k[i]}$ is an additional species-specific effect for the *k*th species applied to effect size *i* [i.e., these are species-specific effects because of shared ecology and other factors, @Cinar2021], $s_{j[i]}$ is the study-specific effect for the *j*th study applied to effect size *i*, $e_{i}$ is the effect size-specific effect (or within study effect, or residuals) for the *i*th effect size, and $m_{i}$ is the sampling variance effect around the *i*th effect as a result of variation in precision among each effect sizes, $v_{i}$, which is known as the sampling variance for the effect. This model is a 'weighted' multilevel meta-analysis model because the estimation of the overall meta-analytic mean, $\beta_{0}$, is partially weighted by the inverse sampling variance of each effect size. Importantly, if we have effect sizes that are derived from the *same* sample of organisms (e.g., because traits are measured on the same sets of individuals) then we need to remove this dependency from the calculation of each $v_{i}$; we can then model the known sampling covariance between effect sizes by modifying $\textbf{I}$ to include off-diagonals that account for this covariance [See Box 1 and @Noble2017]. The fact that we can obtain an overall estimate of sampling variance (i.e., $\sigma^2_{m}$, see below for how it is defined) is very important because it provides a way for us to understand just how much variation in effects are the result of sampling differences across studies versus other, potentially important sources of variation such as differences in the methods applied, species differences or even real biological effects that impact the effect size a study is likely to observe [@Nakagawa2017; @NakagawaSantos2012]. This is formalised in what we call 'heterogeneity analysis' which we describe below. Importantly, this model provides us with the answer to our overall question: Across all the species and studies manipulating egg corticosterone, how much of an overall effect does corticosterone have on reproduction relative to control conditions?

Of course, the overall effect does not provide us with a way to interpret its magnitude in the context of how much CORT has been applied in the treatments used in the sample of studies. The most we can say about it, is that the effect is small, moderate or large out of the sample of effect sizes extracted from this set of studies. In the next section, we show how to 'correct' the overall effect size so that its interpretation is more meaningful.

#### *Multilevel Meta-regression to Understand Variation and Improve Interpretation*

Heterogeneity among effects that result from 'nuisance heterogeneity' can be dealt with using multilevel meta-regression models. Multilevel meta-regression models include all the same random effects that we have already discussed, but they also include fixed effects (i.e., predictors or moderators) that attempt to explain changes in the mean effect size. In other words, we can modify our multilevel meta-analytic model and turn it into a multilevel meta-regression model as follows:

$$ Y_{i} = \beta_{0} + \sum \beta_{j}x_{j} + a_{k[i]} + sp_{k[i]} + s_{j[i]} + e_{i} + m_{i} $$

where $\sum \beta_{j}x_{j}$ is simply the sum of all effects for all moderators (fixed effects), $x_{j}$. All other notation is the same as described above. Importantly, the variable $x_{j}$ could be any moderator collected from studies, including dosage, temperature, salinity, or pH. Some moderators will be at the level of the study (e.g., was the study experimental or observational in nature) but others could be taken at the effect size level (i.e., was the effect derived using a temperature of 23°C or 35°C). By including these moderators in a meta-regression model, the interpretation of the overall meta-analytic mean, $\beta_{0}$, changes. For example, assume we collected the change in CORT dosage relative to a control group (i.e., in µL / g) for our meta-analysis on egg CORT effects on bird reproduction. If the untransformed dosage, $x_{j}$, is included in the model then the overall meta-analytic mean estimate, $\beta_{0}$, would be the mean effect of CORT on reproduction when the dosage difference between the treatment and control group is 0 µL /g. Of course, this interpretation does not make much sense.

We can, however, apply some simple transformations to make the overall mean estimate more intuitive while also improving the interpretation of non-linear parameters and interactions estimated from the model [@Schielzeth2010; @GelmanHill2007]. One simple transformation would be to centre the variable $x_{j}$, by subtracting each value from the mean to create a new input variable (i.e., $c_{i}=x_{i}-\bar{x}$, where the subscript *i* denotes each individual effect size dosage). The new variable, $c_{j}$, is now centered on the mean and can replace $x_{j}$ in the meta-regression model. When the model is refit with $c_{j}$, the estimated $\beta_{0}$ can now be more intuitively interpreted as the overall mean effect of CORT on reproduction at an average dosage difference between treatment and control groups. Importantly, by centering, we retain the original units (µL / g) of the variable, which can be very useful to ease the interpretation of the effect magnitude (e.g., when the dosage difference is 10 µL /g). Given it is very common to estimate and compare overall meta-analytic means (i.e., $B_{0}$) in meta-analyses this centering can be particularly useful in making these means more interpretable. Mean centering can even be extended to include other 'nuisance' variables that might creep into the dataset; the same centering can be done with a second variable, and the overall mean adjusted and interpreted in the context of this new variable along with dosage. Of course, if one is not interested in the magnitude of the effect, we can simply model mean reproductive output as a function of dosage (often what are referred to as 'arm-based' meta-analytic models). Here, one can model the mean for each group (i.e., control and treatment), and account for the known sampling variance associated with each group mean. Dosage, or other continuous variables like temperature, can then be modeled (accounting for sampling variance) to understand how mean reproductive output varies. It is important to recognise that all means need to be comparable and that these models are more complex to fit. While they can be equivalent to 'contrast-based' models, they require complex interactions to be estimated [@Nakagawa2015].

Centering moderator variables, like temperature and dosage, not only provides a way to make the overall mean effect more interpretable in the face of treatment heterogeneity, but it also allows more complex relationships to be fit without compromising interpretations, such as when one includes non-linear parameters (e.g., polynomials) and interactions with other variables. In other words, linear / main effects can still be interpreted normally in the presence of non-linear / interactions fit in the model [@Schielzeth2010; @GelmanHill2007]. We provide examples in the online supplementary material (with R code) to show readers how the models we describe above can be fit, and how meta-analytic means can be adjusted for treatment heterogeneity.

#### *Heterogeneity Analysis: How Much Effect Size Variation Actually Exists?*

As we have already emphasised, quantifying effect size heterogeneity provides the impetus for exploring why effects might vary within and across studies, while also providing context for interpreting the generality of effects. There are a number of measures commonly used to quantify effect size heterogeneity [@Borenstein2019], however, in ecological and evolutionary meta-analysis, heterogeneity is often calculated and reported as $I_{total}^2$ as follows (if using a multilevel meta-analytic model as we describe above):

$$ 
I^2_{total} = \frac{\sigma^2_{study} + \sigma^2_{phylogeny} + \sigma^2_{species} + \sigma^2_{residual}}{\sigma^2_{study} + \sigma^2_{phylogeny} + \sigma^2_{species} + \sigma^2_{residual} +\sigma^2_{m}}
$$

where $\sigma^2_{total} = \sigma^2_{study} + \sigma^2_{phylogeny} + \sigma^2_{species} + \sigma^2_{residual} +\sigma^2_{m}$ is the total effect size variance and $\sigma^2_{m}$ is the total sampling error variance calculated as:

$$
\sigma_{m}^2 = \sum w_{i}\left( k-1\right) / \left[ \left( \sum w_{i}\right)^2  + \sum w_{i}^2\right]
$$

where *k* is the number of studies and the weights, $w_{i} = \frac{1}{v_{i}}$, can be calculated using the inverse of the sampling variance ($v_{i}$) for each effect size, *i*.

Quantifying heterogeneity using $I_{total}^2$ provides a formal way to assess the relative amount of variation that is the result of 'true' biological or methodological differences as opposed to simply chance (i.e., sampling variance) [@NakagawaSantos2012; @Higgins2002]. In other words, $I_{total}^2$ is the percentage of variance between effect sizes after removing the effects of sampling error [@Higgins2002]. Note that we can only calculate this metric if we have an estimate of the sampling variance for a given effect measure because only then can we quantify the proportion of variation that is the result of sampling variability. @Senior2016 have shown that total heterogeneity is often extremely high in ecological and evolutionary meta-analysis (\~91%), suggesting that effect measures vary widely within and across studies. Some of the variation is clearly the result of working with different species and/or strains, or measuring different traits and outcome measures. However, some of this variation also arises because of methodological differences across studies that might be related to the dosages or temperatures used for treatments.

Formally quantifying and presenting heterogeneity estimates from meta-analytic models can provide a way to understand the major drivers of effect size variation by producing various $I^2$ estimates that can be compared within and across studies. For example, we could fit the multilevel model described above to understand what proportion of variation is the result of, say, 'study' effects following @NakagawaSantos2012: $I^2_{study} = \frac{\sigma^2_{study}}{\sigma^2_{total}}$ where $\sigma^2_{study}$ is the study specific variance.

Some readers may notice the similarities between $I^2$ and $R^2$ [@Nakgawa2013; @Nakagawa2010; @Nakagawa2017]. If we want to formally assess how much effect size variation is the result of 'nuisance heterogeneity' (e.g.,  temperature and dosage differences applied across studies) then we could fit our multilevel meta-regression model, including dosage or temperature (linear, quadratic or even more complex fits), and estimate how much variation is explained by these fixed effects following @Nakgawa2013.

$$ R^2_{marginal} = \frac{\sigma^2_{fixed}}{\sigma^2_{fixed} + \sigma^2_{study} + \sigma^2_{phylogeny} + \sigma^2_{species} + \sigma^2_{residual}}$$

Note that this formula does not include $\sigma^2_{m}$ as sampling error variance is assumed to be known in meta-analysis, as explained above. When including continuous moderators, such as dosage, temperature, salinity, and even pH, $R^2_{marginal}$ provides a formal means to assess just how much variation in effects is the result of 'nuisance' heterogeneity at the effect size level. Other biological moderators of interest could also be included as fixed effects and $R^2_{marginal}$ can be calculated for each independently, or all together. Importantly, moderators could be those that explain variation at the effect size level (i.e., dosage, temperature) or variation at the study or species level (e.g., reproductive mode, endothermy etc). $R^2_{marginal}$, or how we like to think of it in this context as $R^2_{'nuisance'}$, maybe a useful measure to help readers understand just how much effect variation can result from the specific treatment application. If the heterogeneity is high as a result of, say, dosages differences, then it is clear that the choice of dosage will have a critical impact on the effect of interest. Comparative physiologists interested in implementing these calculations can do so using our packages `orchaRd` [@Nakagawa2021c] or `metaAidR` (<https://github.com/daniel1noble/metaAidR>).

Heterogeneity described using $I^2$ measures can be useful for understanding the relative contributions of different factors to effect size variation, however, prediction intervals might be more appropriate in many cases [@Nakagawa2021c; @Borenstein2019]. Unlike $I^2$, prediction intervals (PI's) are probably more meaningful in the context of meta-analysis because they explicitly incorporate measures of dispersion around a mean effect size. They provide information about the likely effect size one can expect if we were to randomly sample a new population. For example, assume that we were interested in the overall impact of salinity stress in freshwater fish. To tackle this question, we collected experimental studies measuring fish swim performance under high salinity treatments (\~15-20ppm Na Cl) compared to freshwater (\~0ppm Na Cl) controls; using SMD to quantify the magnitude of effect salinity had on swim performance. We conduct a meta-analysis and estimate an overall SMD of 0.50 with a prediction interval of 0.05 to 0.85. The PI indicates that effects can vary widely from as low as an SMD of 0.05 to as high as an SMD 0.95, depending on the population. In addition, if we were to repeat a study we would expect a new effect to fall within the range of 0.05 and 0.85, 95% of the time [@Borenstein2019; @Nakagawa2021c]. This is a very intuitive interpretation of how variable effects are, yet PIs are often not reported in meta-analyses [@Nakagawa2021c], and we encourage more meta-analysts to report these.

## **Conclusions**

Comparative physiologists are interested in meta-analysing effects across a diversity of species, experimental designs and environments. Importantly, sampling variances for many effect sizes commonly used by comparative physiologists (e.g., CTmax, $Q_{10}$ etc) can be formalised and powerful meta-analytic models can be easily applied. While an overall meta-analytic mean may be of interest, more often than not, understanding the drivers of effect size heterogeneity will be the primary interest. However, factors such as temperature and dosage differences across studies may generate obvious sources of heterogeneity that may not be of prime interest.  Instead, comparative physiologists might simply want to focus on biological drivers of effect size variability and want an effect size or analytic approach that allows them to remove these ‘nuisances’. Here, we provide a set of tools to deal with ‘nuisance heterogeneity’ by ‘reinventing’ standard effect sizes and/or using mean centered nuisance variables in meta-regression models. Estimating complex meta-regression models with a multitude of fixed effects might result, however, in more challenging model interpretation. As such, a combined approach, where some of the known heterogeneity is dealt with by using an appropriate effect size and associated sampling variance while other biologically interesting moderators are fit in a meta-regression model might be desired. Indeed, this may even be a necessity to simplify the model. We wish the set of tools we describe provide clarification around importance and limitations of heterogeneity. We also hope to provide new ways to help comparative physiologists communicate effect measures more richly to guide our understanding and decisions around pressing global challenges.

## **Acknowledgements**

We would like to thank the Editorial board (Craig Franklin, Michaela Handel and Charlotte Rutledge) for inviting us to contribute to this special issue along with feedback on previous drafts. We would also like to than Megan Head for comments on a previous draft. DWAN, SN, ML and REO were supported by ARC Discovery Projects (DP210101152 to DWAN and DP200100367 to SN, ML and DWAN). PP and SB were supported by a UNSW Scientia PhD Scholarship.

## **Author Contributions**
DWAN, SN: Project administration, Conceptualization, Writing - original draft, Visualization, Funding acquisition, Resources, Formal analysis, Methodology, Software; ML, PP, REO, SD, SB: Writing – review & editing, Visualization, Validation, Software, Data curation, Formal analysis.


## **References**
