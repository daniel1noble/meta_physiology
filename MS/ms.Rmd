---
title: "Meta-analytic approaches and 'new' effect sizes to account for heterogeneous effects in comparative physiology"
bibliography: ../bib/refs.bib
csl: ../bib/the-journal-of-experimental-biology.csl
output: 
  bookdown::word_document2:
    toc: no
    toc_depth: 6
    number_sections: false
    reference_docx: template.docx
  bookdown::html_document2:
    code_folding: hide
    number_sections: no
    toc: no
    toc_depth: 6
    toc_float: yes
    bibliography: refs.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
  knitr::opts_chunk$set(echo = FALSE, cache = TRUE, message = FALSE, warning = FALSE, tidy = TRUE, fig.width = 10)
  ## numbers >= 10^5 will be denoted in scientific notation,		  ## numbers >= 10^5 will be denoted in scientific notation,
    ## and rounded to 2 digits		  ## and rounded to 2 digits
    options(digits = 2)
    
  pacman::p_load(flextable, tidyverse, equatags)  
```

Daniel W.A. Noble$^{1,*}$, Patrice Potter$^{2}$, Sammy Burke$^{2}$, Szymek Drobniak$^{2}$, Malgorzata Lagisz$^{2}$, Rose O’Dea$^{2}$, Shinichi Nakagawa$^{2}$

$^{1}$ Division of Ecology and Evolution, Research School of Biology, The Australian National University, Canberra, ACT 2600

$^{2}$ School of Biological, Earth and Environmental Sciences, University of New South Wales, Sydney, NSW 

* Corespondance: 

## **Abstract**

Meta-analysis is a tool that provides comparative physiologists with powerful, unbiased and quantitatively informed answers to topical research questions by synthesising effect sizes across disparate studies. Distilling published research results into standardised effect sizes that can be weighted (i.e., by their inverse sampling variance) in a meta-analysis, and compared across broad sets of research designs, study systems and species is its core objective and strength. Estimating overall effect sizes, and understanding what drives effect variability, provides opportunities to model how organisms will respond to pressing global challenges. Despite this ambition, research designs in comparative physiology can appear, at the outset, as being vastly different to each other (e.g., using different temperatures or treatment dosages). Differences in treatments across studies has led many to believe that meta-analysis is an exercise in comparing “apples with oranges”. Here, we dispel this myth by showing how standardised effects sizes can be used in conjunction with powerful multi-level meta-analytic models to both account for factors driving differences across studies and make them more comparable. In addition, we derive new effect size measures that provide comparative physiologists with a means to directly make effect sizes comparable without the need to resort to more complex statistical models that may be harder to interpret. Our ‘new’ effect sizes and corresponding sampling variances help physiologists deal with common treatment differeces across studies; allowing researchers to compare both mean differences (e.g., $Q_{10}$ to compare mean differences in physiological rates over 10 degrees) and associated differences in variance (e.g, $S_{Q10}$ for comparing variability in in physiological rates over 10 degrees) for physiological traits. The new effect sizes we propose, in combination with existing meta-analytic models, will pave the way for comparative physiologists to explore exciting new questions by making results from large-scale data sets collected from the literature more accessible and widely interpretable.

## **Introduction**
Meta-analysis provides quantitatively informed answers to research questions by using a transparent and reproducible search strategy to synthesise research results across studies and identify sources of variation [@Nakagawa2017; @Gurevitch1999; @Gurevitch2018; @Cooper2009; @Arnqvist1995; @Koricheva2013]. Meta-analysing independent studies provides greater statistical power and precision than what any individual study on its own would be able to provide on a question - particularly given that most empirical studies are already under-powered in many areas of biology [@Forstmeier2017; @Jennions2003; @Button2013]. By expressing study effects on a common scale (i.e., standardised effect size) a meta-analyst can gain broader insight into the direction and efficacy of a particular treatment effect or the strength of a relationship between two variables of interest [@Gurevitch2018; @Koricheva2013]. Quntitative syntheses, including meta-analyses, have provided comparative physiologists with powerful insights on pressing global challenges - from testing whether physiological plasticity can buffer orgamisms against climate change [e.g, @Seebacher2015] to the degree to which endocrine disrupting chemicals, such as bisphenol A (BPA), impact aquatic organisms [e.g., @WuSeebacher2020].

Meta-analysis is a well-developed research field with a long history in statistics, medicine, psychology and ecology [@Gurevitch2018; @Nakagawa2017]. It has emerged as the 'gold-standard' across various disciplines for quantitative synthesis and is becoming increasingly more prominant the field of comparative physiology. Formal meta-analyses involve a systematic literature-based search, extraction of data from studies meeting specific inclusion criteria, and the subsequent calculation of effects sizes from summary statistics provided by papers. The entire process should follow and report upon this entire process carefully to ensure the meta-analysis is as transparent and reproducible as possible [i.e., see the Preferred Reporting Items for Systematic Reviews and Meta-Analyses in Ecology and Evolution (PRISMAEcoEvo) protocol, @ODea2021]. Aside from providing an up-to-date overview of the research question, along with identifying any gaps and biases, there are two major goals of meta-analysis: 1) to provide an overall mean estimate of a treatment effect or relationship and 2) to quantify effect size variance and understand key drivers explaining differences in effects across studies [@Nakagawa2017; @Gurevitch1999; @Gurevitch2018; @Cooper2009; @Koricheva2013]. A critically important feature of meta-analaysis is its ability to account for sampling error [@Koricheva2013]. The inverse sampling error is used to weight higher powered studies in the analysis and make overall estimates more precise. While many meta-analyses might employ unweighted analyses, these studies will not gain greater precision on estimates because sampling variance cannot be formally accounted for in the analysis, even if the overall mean itself is unbiased. 

Despite the widespread adoption and well established methodological procedures of meta-analysis it is often criticised for mixing 'apples and oranges' - in otherwords, mixing effects from studies that lack comparability [@Gurevitch2018; @Arnqvist1995; @Gallo1979; @Carpenter2020; @Stewart2010]. Lack of comparability could result from studies differing in experimental design, species, measurement variables and sampling units, which can impact the generalisability of meta-analytic results [@Arnqvist1995; @Stewart2010]. Indeed, study specific differences in comparative physiology are widspread. For example, experimental designs can vary in the temperatures that they apply or in the dosages of chemical modifiers used in experimental treatments [e.g., @WuSeebacher2020]. In addition, they often include a diversity of study species which can vary in responses. To the uninitiated the concern might not be unfounded given that meta-analyses in ecology and evolution often mix highly heterogenous effect size estimates often resulting in high variability [@Senior2016].

The goal of our review is to briefly overview meta-analytic practices and reassure comparative physiologists that heterogeneity among effect sizes can be comfortably dealt with by modifying existing effect sizes measures and using multilevel meta-regression models. We first conduct a survey of published meta-analyses in the field of comparative physiology to gauge methodological and meta-analytic approaches - assessing what types of effect sizes are commonly used, how often effect size estimates are impacted by continuous treatment differences and whether meta-analytic models (i.e., models that account for sampling variance) are commonly applied. We then introduce new effect sizes and their assocaited sampling variance to provide comparative physiologists opportunities to explictly incorperate treatment differences into the effect size estimates to easy their interpretation. We then describe how more complex treatment differences, such as dosage differences, which may have more complex non-linear effects, can be accomodated using multilevel meta-regression models. Expanding the meta-analtic toolkit for comparative physiologists will provide new opportunities to address global scale problems that attempt to undersatnd how organisms will cope with rapidly changing environments in the future.  

## **Survey of Meta-Analytic Practices in Comparative Physiology**
#### *Literature Search and Survey Data Collection*
To understand meta-analytic practices in comparative physiology, we searched for meta-analyses and comparative analyses that tackled questions that relied on using physiological data compiled from animal studies across multiple species. We were specifically interested in asking: 1) what type of effect size was used within the quantitative synthesis? 2) based on the methods provided, was the effect size likely susceptable to variation in how treatments are applied across studies? 3) If so, was the variation resulting from treatment differences accounted for in the effect size or during analysis?, and finally, 4) how were effect sizes analysed in the quantitative synthesis, were these weighted analyses, and what program was used for analysis? We also recorded whether publication bias and sensitivity analyses were conducted, if data were publicly available, where it was stored and if so it was usable (i.e., in a format like .txt).  All searches were conducted in Scopus between May 16 - 18, 2021. Briefly, we first did a series of pilot searches (detailed in Supplementary Materials) to refine our search query. We searched for studies that included: 'meta-analysis', 'meta regression' , 'comparative analysis', 'comprehensive analysis' 'global analysis' or 'macrophysiology' in their title and abstract, restricting our search to key comparative physiology journals (deatiled in Table X - Supplementary Materials) within the last 6 years. We expected this to provide a contemporay overview of quantitative syntheses in comparative physiology while making the survey and screening feasible. We awknowledge that this may have missed some important, and influential, quantitative synthese in the field of comparative physiology, but likely provided a random sample to inform on the questions we sought to address (see below). 

We included quantitative syntheses, including meta-analyses (*sensu stricto*), that were focused on comparative physiologcial questions only. Narrative reviews and comments were not considered because they did not collate quantitative data from the literature. Studies needed to have collected physiological trait data from the literature including traits, such as hormones, thermal physiology (CTmax, CTmin, thermal preferences, thermal breadth, LT50, lethal thresholds), metabolic rates (routine, maximum, and minimum metabolic rate, aerobic scope), enzyme reaction rates and concentrations, oxidative stress and consequences (e.g., DNA damage, teleomere attrition), performance measurements (e.g., heart rates, sprint speed, swim speed, growth rates), body composition (e.g., fatty acid profiles) and immune traits (e.g., cell function, antibodies, ect.). Studies were also included if they measured the relationship between physiological traits and body size (e.g., metabolic scaling), reproductive allocation, or survival / mortality across taxa. Studies on behavior were only included if the synthesis was explicitly interested in the proximate physiological drivers of behavioral variation. We also included meta-analyses that quantifed plasticity in physiological traits across taxa for the purpose of understanding adaptive plasticity in response to environmental variation. While many studies in comparative physiology collect data as part of a comparative analysis, we focus here only on studies collating data from existing literature because this is the major data source for quantitative synthesis. Quantitative syntheses interested in phenology, biomechanics, sexual size dimorphism (i.e., SSD, except if the study was interested in sexual differences in physiological traits), those focused on validating physiological methodology, or characterising population genetic structure, gene transcription and quantitative genetics were excluded. There were also meta-analyses that focused on colour evolution and contrast which varied in their goals but were most often not focused on physiological questions. As such, these studies were also exclude.  We restricted our focus to animal studies because plant synthesis papers were often only focused on ecological (e.g., quantified changes in abundance and distribution of species) or agricultural questions (e.g., studies on soil microbial function, nitrogen and phosphorus capture, methane output and greenhouse gas emissions).

All title, abstract and full text screening was done by two people (DWAN and ML). Any conflicts or disagreements were resolved by discussion and a concensus on a paper was reached. Out of the 417 papers, 79 full texts were screened and we included a total of 62 for final data extraction. For full details on the search strings used, dates searched, the number of papers found, and our PRISMA flowchart (along with reasons for exclusion at the full text stage) we refer readers to the *Supplementary Materials*. 

#### *Current Meta-analytic Practices in Comparative Physiology*

## **Opening Up New Opportunities in Comparative Physiology: Expanding the Breadth of Effect Sizes to Deal with Treatment Differences Across Studies**
#### *Brief Introduction to Common Effect Sizes and Sampling Errors that are Useful in Comparative Physiology*

Meta-analysis requires comparative physiologists to make use of effect sizes that are suitable for answering their specific question. The key features of all effect sizes used in meta-analyses are that they are: 1) statistical parameters that have been placed on a common scale so that they can be compared across studies and 2) that they have some associated measure of precision (i.e., sampling variance)[@Koricheva2013; @Borenstein2009; @Schmid2021]. Effect sizes in comparative physiology are quite variable; they can be the mean difference between two groups (e.g., difference in mean between a control and treatment group - see @WuSeebacher2020), the slope of a regression (e.g., between body size and metabolic rate), a correlation between two variables, or even the raw mean (or variance) itself (e.g., comparing CTmax across species - see @Sunday2014).  In many cases, multiple types of effect sizes might be used depending on the question. For example, studies interested in the effect of temperature on some physiological trait that have measured the trait across studies experimentally manipulating temperature could analyse the mean 'effect' by creating contrast-based effect sizes or by analysing the mean in each temperature treatment. The choice as to which one to use will boil down to the types of data available from primary studies, the specific question of interest and whether studies are observational or experimental in nature. Considering our temperature example above, if we are interested in the magnitude of change between temperature treatments, we may want to use a contrast-based effect size, such as the log response ratio $ln_{RR}$. If we are instead interested in how the mean of some physiological trait changes with tempearture we may instead model the mean itself. In the latter scenerio, so long as all the means are measured in the same units (e.g., ; or can be converted to the same units) then the mean may provide the desired answer to a given question. We provide details on different effect measures and associated sample sizes in Table \@ref(tab:tablea). 


```{r tablea, echo = FALSE, tab.cap = "Common effect sizes, associated sampling variances and notes on when they might be used. Note that for log odds ratio a continuity correction is applied (i.e., 0.5) to each proportion. In addition, a correction factor, J (1-3 ), is applied to the standardised to correct for small sample effects"}

# I'm just listing a bunch here, but we should think about what we want to include. Here's an example of how we can make a table with all equations. Fun! Really useful website here: https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference. Something wrong with character coding when rendering word document. Has to do with the log odds ratio equation. Renders fine in html, but just stops when word
names <- c("Mean",
           "Variance",
           "Log Response Ratio",
           "Standardised Mean Difference",
           "Zr (Correlation Coefficient)")
           #"Log Odds Ratio",
           #"")
           
eqns_yi <- c("X_{i}",
             "\\sigma^2",
             "log \\left( \\frac{X_{1}}{X_{2}}\\right)",
             "\\frac{\\left( X_{2} - X_{1}\\right)}{sd_{p}}J",
             "\\frac{1}{2}log\\left(\\frac{1+r_{i}}{1-r_{i}}\\right)")
             #"log\\left(\\frac{y_{i2}+0.5}{n_{i2}-y_{i2}+0.5}\\right) ",
             #"- log\\left(\\frac{y_{i1}+0.5}{n_{i1}-y_{i1}+0.5}\\right)")
             
# Just placeholders for now
eqns_vi <- c("\\frac{s_{i}^2}{n_{i}}",
             "\\frac{s_{i}^2}{n_{i}}",
             "\\frac{s_{i}^2}{n_{i}}",
             "\\frac{s_{i}^2}{n_{i}}",
             "\\frac{s_{i}^2}{n_{i}}")
             #"\\frac{s_{i}^2}{n_{i}}",
             #"")
         

table_fin <- data.frame(names, eqns_yi, eqns_vi)

# Note: It is esssential that you be clear that the function 'compose' is exported from the flextable package. That's because purr also has the same function, so it gets messy.
tablea <- flextable(table_fin)                                                                                %>% 
          flextable::compose(j = "names", part = "header", value = as_paragraph(as_b("Effect Measure")))      %>% 
          flextable::compose(j = "eqns_yi", part = "header", value = as_paragraph(as_b("Definition")))        %>% 
          flextable::compose(j = "eqns_vi", part = "header", value = as_paragraph(as_b("Sampling Variance"))) %>%
          flextable::compose(j = "eqns_yi", value = as_paragraph(as_equation(eqns_yi)))                       %>%
          flextable::compose(j = "eqns_vi", value = as_paragraph(as_equation(eqns_vi)))                       %>% 
          flextable::width(j = 1, 3)                                                                          %>% 
          flextable::width(j = 2, 2)

tablea

```


#### *Expanding the Scope of Effect Size Metrics in Comparative Physiology*

A very common occurance in comparative physiology is to manipulate the tempearture organisms experience and measure some physiologcal rate (e.g., metabolic rate). Using normal effect size measures (see above) would result in the effect sizes varying in the types of temperatures applied within and across across studies contributing to 'comparablity' issues. As such, it is often of interest to standardsise effects by temperature. One common effect size measure already used in comparative physiology to compare physiological rates is $Q_{10}$ [e.g., @Rodgers2021; @Seebacher2015; @Havird2020], which describes the multiplicative change in physiological rates across a 10&deg;C temperature change. Higher $Q_{10}$ values indicate larger changes in physiological rates. Currently, however, we do not have associated sampling variances derived for $Q_{10}$ making it challenging to make use of the full power of weighted meta-analytic models. Interstingly, $Q_{10}$ is quite similar to *lnRR*, meaning that we can derive a $Q_{10}$ based effect size and sampling error using the well known mathematical properties of *lnRR*. This opens up the meta-analtic toolbox and improves upon our ability to account for well known sources of non-independence that are typical in meta-analysis [@Lajeunesse2011; @Noble2017]. 

#### *Comparing changes in mean physiological rates*

Prior to showing how the relevant $Q_{10}$ effect size can be calculated it can be helpful to understand its similarities to *lnRR*. The *lnRR* described by @Hedges1999 and extended by  @Lajeunesse2011 and can be calculated as follows:

$$
\begin{equation} 
  \begin{aligned}
  lnRR = ln\left ( \frac{X_{1}}{X_{2}}\right )
  \end{aligned}
  (\#eq:lnRR)
\end{equation} 
$$

$$
\begin{equation} 
  s_{lnRR} = \left ( \frac{SD_{1}^2}{N_{1}X_{1}^2}\right ) + \left ( \frac{SD_{2}^2}{N_{2}X_{2}^2}\right )
  (\#eq:slnRR)
\end{equation} 
$$
In equation \@ref(eq:lnRR), $X_{1}$ is the mean of group 1, often a control group, where as $X_{2}$ is the mean of group 2 (e.g., a treatment group). The mean of $X_{i}$ for group *i* can be any measurement type (e.g. a physiological rate, mass etc) so long as the measurement variable is ratio scale. Log transformation of this ratio makes the effect size normally distributed. Equation \@ref(eq:slnRR) is the analytical solution for *lnRR*'s sampling variance where, $SD_{1}^2$ and $SD_{2}^2$ is the variance in group 1 and 2, respectively and $N_{1}$ and $N_{2}$ is the sample size in group 1 and 2. 

The equations for *lnRR* and its sampling variance allow us to easily extend this to $Q_{10}$ based effect sizes. Recall that $Q_{10}$ is described as follows:

$$
\begin{equation} 
  Q_{10} = \left( \frac{R_{2}}{R_{1}} \right)^{ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
  (\#eq:q10)
\end{equation} 
$$
Here, $R_{1}$ and  $R_{2}$ are mean physiological rates and  $T_{1}$ and  $T_{2}$ are the temperatures that these rates are measured. Log transformation of equation \@ref(eq:q10) leads to the following log transformed $Q_{10}$:

$$
\begin{equation} 
  lnRR_{Q_{10}} = ln\left( \frac{R_{2}}{R_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
(\#eq:lnq10)
\end{equation} 
$$
Equation \@ref(eq:lnq10) is essentially a temperature corrected equivalent to lnRR when the numerator and denomenator are measured at different temperatures. This allows one to compare the mean of two temperature treatments directly regardless of the temperatures that these groups have been measured. Here, we will refer to this as the log $Q_{10}$ response ratio, $lnRR_{Q_{10}}$. Recognition of this equivalence means that we can easily calculate the sampling variance for equation \@ref(eq:lnq10) as follows:

$$
\begin{equation} 
  s_{lnRR_{Q_{10}}} = \left( \frac{SD_{2}^2}{R^2_{2}N_{2}} + \frac{SD_{1}^2}{R^2_{1}N_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }^2
  (\#eq:Vlnq10)
\end{equation} 
$$

#### *New Effect Size Metrics that Compare Changes in Variability Across Treatments*

@Nakagawa2015 recently proposed analogous effect size estimates to *lnRR* that allow for comparisons of changes in variance between two groups, the log variance ratio (*lnVR*) and the log coefficient of variation (*lnCVR*). Like *lnRR*, *lnVR* and *lnCVR* are ratios that describe the relative difference in trait variablity between two groups. We refer readers to @Nakagawa2015 for the equations describing *lnVR* and *lnCVR*, but these can easily be extended to their $Q_{10}$ analogues (and associated sampling variances) as follows:

$$
\begin{equation} 
lnVR_{Q_{10}} = ln\left( \frac{SD_{2}}{SD_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
(\#eq:lnq10VR)
\end{equation} 
$$
$$
\begin{equation} 
s_{lnVR_{Q_{10}}} = \left( \frac{1}{2\left( N_{2}-1 \right)} + \frac{1}{2\left(N_{1} - 1\right)} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }^2
(\#eq:slnq10VR)
\end{equation} 
$$

Equations \@ref(eq:lnq10VR) and \@ref(eq:slnq10VR) describe the change in physiological rate variance (eqn \@ref(eq:lnq10VR)) across a 10&deg;C temperature change along with its sampling variance (eqn \@ref(eq:slnq10VR)). While this is a useful metric, as discussed by @Nakagawa2015 there is often a strong mean-variance relationship that needs to be accounted for in analysing changes in variance. As such, we can calculate the coefficient of variation, which standardises changes in variance for changes in means as follows:

$$
\begin{equation} 
lnCVR_{Q_{10}} = ln\left( \frac{\text{CV}_{2}}{\text{CV}_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
(\#eq:lnq10CVR)
\end{equation} 
$$
$$
\begin{equation} 
s_{lnCVR_{Q_{10}}} = \left[ \frac{(\text{SD}_{1})^2}{N_{1}({R}_{1})^2} + \frac{(\text{SD}_{2})^2}{N_{2} ({R}_{2})^2} + \frac{1}{2\left( N_{1}-1 \right)} + \frac{1}{2\left(N_{2} - 1\right)} \right]{ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }^2
(\#eq:slnq10CVR)
\end{equation} 
$$

where $CV$ is the coefficient of variation defined as $SD / R$. 

## **Meta-Analytic Models to Control for Heterogeous Effects Within and Across Studies**

It will not be possible to derive an effect size that completely controls for known heterogenity at the effect size level all the time. This may because because treatment effects may not be simple linear or exponential functions of the mean response making the relationship with effect size complex [e.g., thermal performance curves; @Noble2018]. For example, dosages applied to treatments can follow quite complex non-linear relationships, with expoential or quadratic relationships in relation to some mean response. When this occurs we recommend comparative physiologists apply meta-regerssion approaches, controlling for these known treatment differences as a moderator. There are simple statisical approaches a meta-analyst can use to then make the overall effects interpretable [@Schielzeth2010]. Before diving into meta-regression models, we will first overview the meta-analytical approaches or steps commonly used.

#### *Multi-level Meta-Analysis when the Overall Effect is of Interest*
One of the main goals of meta-analysis is to obtain an overall meta-analytic mean effect size estimate and some form of uncertainty around that mean, like a 95% confidence interval (CI). Including a prediction interval (PI) can also be quite useful because, in the context of a meta-analysis, it provides the range of effect size values we might expect to observe if a new study were to be conducted [@Nakagawa2021c]. Estimating an overall mean along with 95% CI (or PI) is generally done with a simple random effects or multilevel meta-analytic model that accounts for effect size sampling error [@Nakagawa2017; @NakagawaSantos2012]. More often than not, meta-analyses in comparative physiology will have complex hierachical structure. For example, multiple effect sizes may be taken from a single study on different traits measured on the same individuals, or come from many different species that share an evolutionary history [@Noble2017]. As such, it is far more likely that comparative physiologists will need to apply a multi-level meta-analytic model to control for the various sources of non-independence [@NakagawaSantos2012; @Song2021; @Nakagawa2021; @Noble2017]. Multilevel models are also extremely useful in describing the various sources contributing to effect size variance. For the purpose of our discussion, we will assume the meta-analyst plans to use more advanced multilevel models. Having said that, it maybe sufficient for many meta-analyses to make use of traditional random effects models. We refer readers to excellent reviews and books that overview the distinctions between common (fixed) effect, random effect and multilevel models and when one might want (or not want) to apply these models [@Nakagawa2017; @NakagawaSantos2012; @Koricheva2013; @Borenstein2009; @Schmid2021]. 

If we assume that we are interested in understanding the overall effect of, say, stress (i.e., corticosterone) on XX we might extract data from studies manipulating corticosterone on eggs. Of course, these studies are diverse, apply different dosages of corticosterone and are working across many species. If the studies are experimental in nature, than a standardised effect size, such as $ln_{RR}$ might be applicable. We then might fit an overall, multilevel meta-analytic model as follows:

$$ z_{i} = u + a_{k[i]} + sp_{k[i]} + s_{j[i]} + e_{i} + m_{i} $$

where $z_{i}$ is the *i*th effect size (*i* = 1 ... $N_{ES}$, the number of effect sizes), *u* the overall meta-analytic mean, $a_{k[i]}$ is the phylogenetic effect for species *k* applied to effect size *i*. Phylogenetic effects are assumed to be normally distributed deviates sampled from a distribution with a mean of 0 and variance $\sigma^{2}_aA$ [hereafter denoted ~ *N*$(0, \sigma^{2}_aA)$], where A is a phylogenetic correlation matrix derived from a phylogenetic tree, $sp_{k[i]}$ is the species-specific effect for the *k*th species applied to effect size *i* [assumed to be ~ *N*$(0, \sigma^{2}_{sp}I)$], $s_{j[i]}$ is the study-specific effect for the *j*th study applied to effect size *i* [assumed to be ~ *N*$(0, \sigma^{2}_{s}I)$, where I is an identity matrix], $e_{i}$ is the effect size-specific effect (or within study effect, or residuals) for the *i*th effect size [assumed to be ~ *N*$(0, \sigma^{2}_eE)$], and $m_{i}$ is the sampling variance effect around the *i*th effect as a result of variation in precision among each effect size [assumed to be  ~ *N*$(0, M)$], where M is a variance-covariance matrix with the diagonal elements being the effect size sampling variance. This model is a 'weighted' multilevel meta-analysis model because we can estimate the overall sampling variance. This is very important because it provides a way for us to understand just how much variation in effects are simplly the result of sampling differences across studies versus other, potentially improtant sources of variation such as differences in the methods applied, species differences or even real biological effects that impact the effect size a study is likely to observe. This is formalised in what we call 'heterogenetiy analysis' which we describe below. Importantly, this model provides us with the answer to our overall question: Across all the species and studies manipulating corticosterone, how much of an overall effect does corticostrone have on XX relative to control conditions?

#### *Heterogenity Analysis: How Much Effect Size Variation Actually Exists?*
Quantifying effect size heterogenity (i.e., effect size variance) provides a pathway to explore hypotheses thought to explain why effects might vary within and across studies. Effect size heterogeneity can be thought of as the percentage of variance between effect sizes that cannot be attributable to sampling error (often as called 'total' heterogenity) [@Higgins2002]. More formally, we can quantify heterogenity using the multilevel meta-analytic model we describe above as:

$$ I^2_{total} = \frac{\sigma^2_{total} - \sigma^2_{m}}{\sigma^2_{total}} $$
where $\sigma^2_{total}$ is the  total effect size variance (using the above multilevel model than $\sigma^2_{total} = \sigma^2_{study} + \sigma^2_{phylogeny} + \sigma^2_{species} + \sigma^2_{residual} +\sigma^2_{m}$) and $\sigma^2_{m}$ is the total sampling error variance.  Quantifying heterogenity provides a formal way to assess how much variation is the result of 'true' biological or methodological differences as opposed to simply chance (i.e., sampling variance) [@NakagawaSantos2012; @Higgins2002]. We can only conduct such analyses if we have an estimate of the sampling variance for a given effect measure because only then can we quantify how much variation is the result of sampling variability. @Senior2016 have shown that total heterogenity is often extremely high in ecological and evolutionary meta-analysis (~91%), suggesting that effect measures vary widely across and within studies. Some of the variation is clearly the result of working with different species or strains, different traits and different outcome measures, however, some of this variation also arises because of methodological differences across studies that might be related to the dosages or temperatures used for treatments. Formally quantifying and presenting heterogenity estimates from meta-analytic models can provide a way to undersand the major drivers of effect size variation by allowing researchers to produce various $I^2$ estimates which can be formally compared within and across studies. For example, we could fit the multilevel model described above to understand what proportion of variation is the result of, say, 'study' effects following @NakagawaSantos2012:

$$ I^2_{study} = \frac{\sigma^2_{study}}{\sigma^2_{study} + \sigma^2_{phylogeny} + \sigma^2_{species} + \sigma^2_{residual} +\sigma^2_{m}} $$
where $\sigma^2_{study}$ is the study specific variance, and all other variance components are for phylogeny, species, residual (effect size level) and m (total measurement/sampling error). Many readers will notice the similarities between $I^2$ and $R^2$ [@Nakgawa2013; @Nakagawa2010]. If we want to formally assess how much effect size variation is the result of methodological factors, such as temperature and dosage differences applied across studies, then we could fit our multilevel meta-regression model, including dosage or temperature (linear, quadratic or even more complex fits), and estimate how much variation is explained by these fixed effects. 


** NOTE THAT WE MAY WNAT TO SWITCH POSITION, INTRODUCE METEREGRESSION FIRSTs

#### *Multi-level Metaregression to Understand Variation and Improve Interpretation*

## **Conclusions and Future Directions**

## **References**
