---
title: "Supplemental Materials for: Meta-analytic approaches and new effect sizes to account for heterogeneous effects in comparative physiology"
author: Daniel W.A. Noble, Patrice Potter, Sammy Burke, Szymek Drobniak, Malgorzata Lagisz, Rose O’Dea, Shinichi Nakagawa
date: "`r Sys.Date()`"
bibliography: ../bib/refs.bib
csl: ../bib/the-journal-of-experimental-biology.csl
output: 
  bookdown::html_document2:
    code_folding: hide
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
  bookdown::word_document2:
    toc: no
    toc_depth: 6
    number_sections: false
    reference_docx: template.docx
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, tidy = TRUE)
options(digits=2)
```

```{r klippy, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
#install.packages("devtools")
remotes::install_github("rlesur/klippy")
klippy::klippy(tooltip_message = 'Click to Copy Code', tooltip_success = 'Done', position = 'right', color = "red")
```

# Citation
This supplement is associated with a special issue review paper and can be cited as follows:

Daniel W.A. Noble, Patrice Potter, Sammy Burke, Szymek Drobniak, Malgorzata Lagisz, Rose O’Dea, Shinichi Nakagawa (2022) *Meta-analytic approaches and "new" effect sizes to account for heterogeneous effects in comparative physiology*. **Journal of Experimental Biology**

# Introduction

In this supplement we will demonstrate some of the principles we describe in our review paper. We'll show readers ways they can apply some of the 'new' effect sizes we describe to account for 'nuisance heterogeneity' in combination with multilevel meta-analytic models (MLMA) and/or multilevel meta-regression models. We realise that 'nuisance heterogeneity' may be a misnomer in some senses because such forms of heterogeneity may actually be the main interest of a given meta-analysis; in which case, multilevel meta-regressions are the way to go! 

We will overview two different case studies. The first case study will show readers how to account for known drivers of effect heterogeneity in the effect size, followed by how we can fit a MLMA (intercept only) model to estimate an overall meta-analytic mean. We then show readers how to interpret this mean and associated heterogeneity. In the second case study, we use a common effect size metric and instead model the 'nuisance' heterogeneity using a multi-level meta-regression approach. We also focus on showing readers how to interpret effects from this model along with heterogeneity. 

Throughout the supplement R code is contained within code blocks. We provide example data associated with this tutorial which readers can find on the [Open Science Framework](https://osf.io/wscz5/), but the code chunks should automatically download and load these for you. Importantly, all relevant code chunks have a 'copy and paste' button in the top right corner so that the code can be easily transferred to your own R console. 

# Loading Data and R Packages

Before embarking on the case studies readers will need to load the necessary R packages. Note that the first two lines are commented out. If you don't have these packages, just install these by removing the `#`. 

```{r loadpackages, echo = TRUE, results = "hide", messages = FALSE, class.source='klippy'}
#install.packages("pacman")
#devtools::install_github("itchyshin/orchard_plot", subdir = "orchaRd", force = TRUE)
pacman::p_load(devtools, png, jpeg, pander, cowplot, flextable, tidyverse, metafor, orchaRd, here, osfr, magrittr)
```

# Case Study 1: Multilevel meta-analysis approaches to control for differences in treatment magnitude

Here, we will demonstrate how to use analyse variation in slopes and differences in slopes between two groups. In this example, we will account for effects of known drivers of 'nuisance heterogeneity' at the level of the effect size. We use a case study by Pottier et al. *in review* which investigated the association between acclimation temperature, thermal tolerance and sex. We first demonstrate how to use meta-analytic approaches to investigate the variation in the relationship between acclimation temperature and thermal tolerance (i.e. variation in slope), and then demonstrate how to meta-analyse differences in slopes between two groups (i.e. sexes). 

## Multilvel meta-analysis of slopes

We first download the data from OSF, and load this into R. You can do this by copying and pasting the code below.

```{r class.source='klippy'}

# Download the data file from OSF
osfr::osf_retrieve_file("https://osf.io/qn2af/") %>% osfr::osf_download(conflicts = "overwrite") 

# Load the data file
data_CS1a <- read.csv(here::here("ms", "CTmax_ARR.csv"))
```

### Calculate Effect Size

In this section, we demonstrate how to calculate slope effect sizes and their associated sampling variance. Note that calculating slopes require the response variable to be measured with the same unit and does not apply to all meta-analyses. While this example focuses on thermal tolerance, the meta-analysis of slope may also be applicable to investigate changes in thermal preference, or metabolic scaling for example. 

In this example, we use a simplified data set from Pottier et al. *in review* and we demonstrate how to investigate the mean effect of acclimation temperature on heat tolerance. Because heat tolerance was consistently measured in degrees Celsius (`CTmax`) in the studies compiled, we can calculate the slope between acclimation temperature and heat tolerance, which is termed as the acclimation response ratio (`ARR`) in the literature. 
This effect size is calculated as the difference between the heat tolerance at the higher (`mean_high`) and the lower (`mean_low`) acclimation temperatures, divided by the difference between acclimation temperatures (`acc_temp_high` - `acc_temp_low`). 
The sampling variance of the slope (`Var_ARR`) can then be defined using properties of variance as per 'formula XXX` 

In this example, the slopes were calculated with stepwise comparisons between acclimation treatments. This method created a source of non-independence, with some treatments being involved in multiple comparisons (`shared_trt_ID`).
To account for this, we divided by half the sample size of the observations in these non-independent comparisons (`n_low_adj` and `n_high_adj`) to divide by half the weight of these estimates. 

```{r, class.source='klippy', results = 'hide'}
data_CS1a<-data_CS1a %>% 
              mutate(ARR=(mean_high-mean_low)/(acc_temp_high - acc_temp_low),
                     Var_ARR=((1/(acc_temp_high-acc_temp_low))^2*(sd_low^2/n_low_adj+sd_high^2/n_high_adj))) # Need to double check this formula, Shinichi pointed out that there might be a mistake.
```

In some cases, CTmax was measured twice on the same cohort of animals (e.g. using a different endpoint), which generates a source of non-independence between effect sizes. We can account for this source of non-independence by correlating errors between dependent effect sizes. The `make_VCV_matrix` from [`metaAidR`](https://github.com/daniel1noble/metaAidR) is a handy function to perform this correction, and assume a correlation of r = 0.5 by default. We termed the created variance-covariance matrix `VCV_ARR`. 

```{r, class.source='klippy', results = 'hide'}
# Variance covariance matrix to account for non-independence of measurements performed on the same cohorts of animals
VCV_ARR<- metaAidR::make_VCV_matrix(data_CS1a, V = "Var_ARR", cluster = "shared_measurement_ID", obs = "es_ID")
```

### Meta-analysis

Then, we can run the multi-level meta-analytic model using the `rma.mv` function in the `metafor` package. 
In this model, we used two random effects: `species_ID` and `es_ID` to account for between species variation and the variation associated with the residuals. Note that it is possible to assess the variation due to phylogenetic relatedness but we will keep it simple for demonstration purposes. We also did not assessed variation due to between-study differences because the levels of this variable was almost entirely overlapping with `species_ID` (i.e. `species_ID` and `study_ID` were indistinguishable). 
While we only present  an intercept-only model, this structure can be used to fit meta-regressions by fitting moderator variables. 

```{r, class.source='klippy', results = 'hide'}
# Multi-level meta-analytic model
Model_CS1a_MLMA<-metafor::rma.mv(yi=ARR~-1, V=VCV_ARR, 
                   method="REML",
                   random=list(~1|species_ID,
                               ~1|es_ID), 
                   test="t",
                   dfs = "contain",
                   data=data_CS1a)
summary(Model_CS1a_MLMA)

# Calculate Prediction Intervals
PIs_CS1a_MLMA <- predict(model_CS1a_MLMA)
print(PIs_CS1a_MLMA)

# Calculate I2
I2_CS1a <- orchaRd::i2_ml(Model_CS1a_MLMA)
print(I2_CS1a)
```


## Multi-level Meta-analysis of slope differences between two groups 

We can imagine cases where one might be interested in comparing the slopes of two groups or treatments. 
In this example, we demonstrate how to derive and analyse effect sizes when investigating differences in slopes. As per the previous example, such analysis require responses variables to be measured with the same unit. 
We use the same data set as before, but formatted in a slightly different way (i.e. columns were re-organised in a "wide" format to calculate differences between sexes). In this example, rather than investigating overall variation in `ARR`, we will investigate the difference in `ARR` between males and females. 

```{r class.source='klippy'}
# Download the data file from OSF
osfr::osf_retrieve_file("https://osf.io/zubky/") %>% osfr::osf_download(conflicts = "overwrite") 

# Load the data file
data_CS1b <- read.csv(here::here("ms", "CTmax_ARR_sex.csv"))
```

### Calculate effect size 

First, we need to calculate the `ARR` of females (`ARR_f`) and males (`ARR_m`) with the formula we presented earlier. 
We can then use the mean difference between `ARR_f` and `ARR_m` as an effect size, which we term here as `ARRD`. 
The sampling variance was then calculated as per `formula XXX`

```{r, class.source='klippy', results = 'hide'}
data_CS1b<-data_CS1b %>% # calculate effect sizes

  mutate(ARR_f=((mean_high_f-mean_low_f)/(acc_temp_high-acc_temp_low))) %>% 
  mutate(ARR_m=((mean_high_m-mean_low_m)/(acc_temp_high-acc_temp_low))) %>% 
  mutate(ARRD=ARR_f - ARR_m) %>% 
  mutate(Var_ARRD=((1/(acc_temp_high-acc_temp_low))^2*(sd_low_f^2/n_low_f_adj+sd_high_f^2/n_high_f_adj+sd_low_m^2/n_low_m_adj+sd_high_m^2/n_high_m_adj)))  
```

### Meta-analysis

Again, we first started by accounting for the non-independence of CTmax estimates measured on the same cohorts using a variance-covariance matrix termed as `VCV_ARRD`. 
We then fit a multi-level meta-analytic model using a similar structure as demonstrated before. 
Note that this model can be extended to meta-regressions by fitting moderator variables. 
```{r, class.source='klippy', results = 'hide'}

# Variance covariance matrix to account for non-independence of measurements performed on the same cohorts of animals
VCV_ARRD<- metaAidR::make_VCV_matrix(data_CS1b, V = "Var_ARR", cluster = "shared_measurement_ID", obs = "es_ID")

# Multi-level meta-analytic model
model_CS1b_MLMA<-metafor::rma.mv(yi=ARRD~-1, V=VCV_ARRD, 
                   method="REML",
                   random=list(~1|species_ID,
                               ~1|es_ID), 
                   test="t",
                   dfs = "contain",
                   data=data_CS1b)
print(model_CS1b_MLMA)

# Calculate Prediction Intervals
PIs_CS1b_MLMA <- predict(model_CS1b_MLMA)
print(PIs_CS1b_MLMA)

# Calculate I2
I2_CS1b <- orchaRd::i2_ml(model_CS1b_MLMA)
print(I2_CS1b)
```


# Case Study 2: Multilevel Meta-regression Approaches to Control for Dosages

In the next case study we'll demonstrate how to use multilevel meta-regression models to correct overall meta-analytic means for dosage differences applied across studies. The data in question was collected by @Podmola2018. 

### Retrieve and Load the Data

We'll first download the data from OSF, and load this into R. You can do this by copying and pasting the code below.

```{r, class.source='klippy', results = 'hide'}

# Download the data file from OSF
osfr::osf_retrieve_file("https://osf.io/j85h3/") %>% osfr::osf_download(conflicts = "overwrite")

# Load the data file.
data_CS2 <- read.csv(here::here("ms", "Dosage_EggHormones_CS2.csv"), sep = ";")

```

### Interpreting Meta-analytic Means Controlling for Dosages
The data contains two columns of dosages....EXPLAIN all this.

```{r, class.source='klippy', results = 'hide'}
# Centre the dosage data on the mean. Note that, for comparability, we'll exclude 'NA' in dose so that models are fit with the exact same data.
          data_CS2 %<>% mutate(z_total_dose_T = scale(total_dose_T, center = TRUE, scale = FALSE)) %>% filter(!is.na(z_total_dose_T))

# Model that ignores "nuisance heterogeneity" for dosage applied
     model_CS2_MLMA <- metafor::rma.mv(d ~ 1, V = var_d, random = list(~1|ID, ~1|paper), test = "t", dfs = "contain", data = data_CS2)
     print(model_CS2_MLMA)
     
# Calculate Prediction Intervals
           pis_MLMA <- predict(model_CS2_MLMA)
           print(pis_MLMA)

# Calculate I2 as well
                 I2 <- orchaRd::i2_ml(model_CS2_MLMA)
                 print(I2)
```

We can see from above that the model 'ignoring' the nuisance heterogenity (model_CS2_MLMA) (i.e., the variability in effects resulting from dosage differences across studies) estimates an overall meta-analytic mean as `r coef(model_CS2_MLMA)` with a 95\% CI from `r model_CS2_MLMA$ci.lb` to `r model_CS2_MLMA$ci.ub`. Our prediction intervals suggest that heterogenity is high, reflected also in our $I_{total}^2$ estimate of `r I2[1]*100`\% -- 95\% of the time we expect the mean in repeated samples to fall between `r pis_MLMA$pi.lb` to `r pis_MLMA$pi.ub`. Approximately, `r I2[3]*100`\% of the total heterogenity is the result of differences between studies. Given that we have not controlled for dosage differences across studies all we can say is that the average SMD is rather small is the sample of studies that have applied these sets of dosages. In otherwords, on average, the means from the treatment and control groups differ by `r coef(model_CS2_MLMA)` standard deviation units. 

We can now model these dosage effects to control for 'nuisance heterogenity' and make the overall mean more interpretable. We'll first start by fitting and interpreting the coefficient just for the raw total dosage applied in a given study. To do this, we can now fit a multilevel meta-regression model as follows:

```{r}

# Model that re-calibrates the overall meta-analytic mean (Intercept) to control for dosage administration
    model_CS2_nuisance1 <- metafor::rma.mv(d ~ total_dose_T, V = var_d, random = list(~1|ID, ~1|paper), test = "t", dfs = "contain", data = data_CS2)
    print(model_CS2_nuisance1)
```

We can see from our model that controls for nuisance heterogenity (model_CS2_nuisance1) that we now estimate an overall meta-analytic mean as `r coef(model_CS2_nuisance1)[1]` with a 95\% CI from `r model_CS2_nuisance1$ci.lb[1]` to `r model_CS2_nuisance1$ci.ub[1]`. Importantly, this is the mean effect size when the total dosage applied is 0, which doesn't make much sense. As such, we can center total dosage applied to make the mean more 'meaningful' (mind the pun). 

```{r}

# Model that re-calibrates the overall meta-analytic mean (Intercept) to control for dosage administration but uses centered dosage
     model_CS2_nuisance2 <- metafor::rma.mv(d ~ z_total_dose_T, V = var_d, random = list(~1|ID, ~1|paper), test = "t", dfs = "contain", data = data_CS2)
     print(model_CS2_nuisance2)

# Calculate Prediction Intervals
           pis_nuisance2 <- predict(model_CS2_nuisance2, newmods = 0)
           print(pis_nuisance2)
# Calculate I2 as well
            I2_nuisance2 <- orchaRd::i2_ml(model_CS2_nuisance2)
            print(I2_nuisance2)
```

Now that we have centered the total dosage around its mean (which is `r mean(data_CS2$total_dose_T, na.rm = TRUE)` uL difference(Szymek, not sure on units, sorry)) our overall meta-analytic mean (now estimated to be `r coef(model_CS2_nuisance2)[1]`,  with a 95\% CI from `r model_CS2_nuisance2$ci.lb[1]` to `r model_CS2_MLMA$ci.ub[1]`) is interpreted differently. Overall, the meta-analytic mean difference between treatments that differ by an average of `r mean(data_CS2$total_dose_T, na.rm = TRUE)` uL is `r coef(model_CS2_nuisance2)[1]` standard deviation units different. Its still a small overall effect size, but it has a clearer interpretation now. We can again calculate PI's and $I^2$ using the model. Overall, our prediction intervals suggest that heterogenity is still high even after accounting for dosage reflected also in our $I_{total}^2$ estimate of `r I2_nuisance2[1]*100`\% --  95\% of the time we expect the mean in repeated samples to fall between `r pis_nuisance2$pi.lb[1]` to `r pis_nuisance2$pi.ub[1]` when the average dosage difference applied is `r mean(data_CS2$total_dose_T, na.rm = TRUE)` uL. 

# Supplementary Materials for Survey Study Selection

Here we provide greater detail on the search strategy, keyword selection and the numbers of final studies included at each step pf the screening process for our survey. Figure \@ref(fig:figS1) outlines our PRSIMA flowchart detailing the number of papers hit, their sources and how many records were excluded and included at each screening phase. The full search strings used to refine our search query can be found in Table \@ref(tab:tabS1). Note that results from our final searches (25 & 28) are the ones we used. Our query was restricted to a pre-specified set of comparative physiology journals within the last 6 years of publication. The journals used and their ISSN numbers are provided in Table \@ref(tab:tabS2). In total, out of the 79 papers screened at the full-text stage we ended up including 62 full texts. We excluded N = 17 meta-/comparative analyses because they: 1) did not include physiological traits (N = 4); 2) were empirical studies that collected their own data and did not collate data from the literature (N = 10); 3) Were not actual quantitative syntheses, but rather systematic reviews (N = 1) and 4) were studies with a focus on biomechanics (N = 2).

```{r figS1, fig.align='center', echo = FALSE, fig.cap="PRISMA flowchart for study selection and inclusion"}

img1 <- readPNG("../figs/PRISMA_diagram_v0.png")

p1 <- cowplot::ggdraw()+
        cowplot::draw_image(img1)
p1
```



```{r tabS1,  echo = FALSE, tab.cap="Log of search string development"}

table <- read.csv("../tables/Table_S1.csv")

table_s1 <- flextable(table)                                                                            %>% 
            flextable::compose(j = 1, part = "header", value = as_paragraph(as_b("Date")))              %>% 
            flextable::compose(j = 2, part = "header", value = as_paragraph(as_b("Search Number")))     %>% 
            flextable::compose(j = 3, part = "header", value = as_paragraph(as_b("Search String")))     %>% 
            flextable::compose(j = 4, part = "header", value = as_paragraph(as_b("Number of Records"))) %>% 
            flextable::compose(j = 5, part = "header", value = as_paragraph(as_b("Comments")))          %>% 
            flextable::compose(j = 6, part = "header", value = as_paragraph(as_b("Notes"))) 
 table_s1
```


```{r tabS2, echo = FALSE, tab.cap="Log of search string development"}

table <- read.csv("../tables/Table_S2.csv")

table_s2 <- flextable(table)                                                                            %>% 
            flextable::compose(j = 1, part = "header", value = as_paragraph(as_b("Journal Name")))      %>% 
            flextable::compose(j = 2, part = "header", value = as_paragraph(as_b("ISSN Number")))       %>% 
            flextable::width(j = 1, 5)
table_s2
```

# Session Information

```{r}
pander(sessionInfo(), locale = FALSE)
```

# References
